"""
ç§‘ç ”çº§ç­–ç•¥ç®¡ç†å™¨
Scientific Strategy Manager for Research-Grade Analysis
ä¸“é—¨é’ˆå¯¹å­¦æœ¯ç ”ç©¶å’Œè®ºæ–‡å‘è¡¨çš„ä¸¥è°¨åˆ†ææµç¨‹
"""

import json
import pandas as pd
import numpy as np
import time
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

class ResearchPhase(Enum):
    """ç ”ç©¶é˜¶æ®µæšä¸¾"""
    EXPLORATORY = "exploratory"           # æ¢ç´¢æ€§åˆ†æ
    BASELINE_ESTABLISHMENT = "baseline"   # åŸºçº¿å»ºç«‹
    FEATURE_ENGINEERING = "feature_eng"   # ç‰¹å¾å·¥ç¨‹
    MODEL_DEVELOPMENT = "model_dev"       # æ¨¡å‹å¼€å‘
    VALIDATION = "validation"             # éªŒè¯é˜¶æ®µ
    INTERPRETATION = "interpretation"     # æ¨¡å‹è§£é‡Š
    REPRODUCIBILITY = "reproducibility"   # å¯é‡ç°æ€§éªŒè¯

class MethodologicalRigor(Enum):
    """æ–¹æ³•å­¦ä¸¥è°¨ç¨‹åº¦"""
    STANDARD = "standard"                 # æ ‡å‡†åˆ†æ
    RIGOROUS = "rigorous"                # ä¸¥è°¨åˆ†æ
    PUBLICATION_READY = "publication"     # å‘è¡¨çº§åˆ«

@dataclass
class ResearchStrategy:
    """ç§‘ç ”ç­–ç•¥é…ç½®"""
    name: str
    description: str
    phase: ResearchPhase
    rigor_level: MethodologicalRigor
    research_objectives: List[str]
    methodological_considerations: List[str]
    expected_outputs: List[str]
    validation_requirements: List[str]
    reporting_standards: List[str]
    estimated_time: int  # åˆ†é’Ÿ
    
class ScientificStrategyManager:
    """ç§‘ç ”çº§ç­–ç•¥ç®¡ç†å™¨"""
    
    def __init__(self, workspace_dir: str = "."):
        self.workspace_dir = Path(workspace_dir)
        self.research_log = []  # ç ”ç©¶æ—¥å¿—
        self.methodology_record = {}  # æ–¹æ³•å­¦è®°å½•
        self.results_dir = self.workspace_dir / "research_outputs"
        self.results_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–ç§‘ç ”ç­–ç•¥
        self._initialize_research_strategies()
        
    def _initialize_research_strategies(self):
        """åˆå§‹åŒ–ç§‘ç ”çº§ç­–ç•¥"""
        
        self.strategies = {
            # 1. æ•°æ®æ¢ç´¢ä¸è´¨é‡è¯„ä¼°
            "data_exploration": ResearchStrategy(
                name="æ•°æ®æ¢ç´¢ä¸è´¨é‡è¯„ä¼°",
                description="ç³»ç»Ÿæ€§æ•°æ®æ¢ç´¢ã€ç¼ºå¤±å€¼åˆ†æã€åˆ†å¸ƒæ£€éªŒ",
                phase=ResearchPhase.EXPLORATORY,
                rigor_level=MethodologicalRigor.RIGOROUS,
                research_objectives=[
                    "è¯„ä¼°æ•°æ®è´¨é‡å’Œå®Œæ•´æ€§",
                    "è¯†åˆ«æ½œåœ¨çš„æ•°æ®åå€š",
                    "æ£€éªŒå˜é‡åˆ†å¸ƒçš„æ­£æ€æ€§",
                    "å‘ç°æ•°æ®ä¸­çš„å¼‚å¸¸æ¨¡å¼"
                ],
                methodological_considerations=[
                    "ä½¿ç”¨å¤šç§ç¼ºå¤±å€¼æ¨¡å¼æ£€æµ‹æ–¹æ³•",
                    "è¿›è¡ŒShapiro-Wilkæ­£æ€æ€§æ£€éªŒ",
                    "è®¡ç®—å˜é‡é—´çš„ç›¸å…³æ€§çŸ©é˜µ",
                    "ç”Ÿæˆè¯¦ç»†çš„æè¿°æ€§ç»Ÿè®¡"
                ],
                expected_outputs=[
                    "æ•°æ®è´¨é‡æŠ¥å‘Š",
                    "ç¼ºå¤±å€¼æ¨¡å¼åˆ†æ",
                    "å˜é‡åˆ†å¸ƒå›¾è¡¨",
                    "ç›¸å…³æ€§çƒ­åŠ›å›¾"
                ],
                validation_requirements=[
                    "ç»Ÿè®¡æ£€éªŒç»“æœè®°å½•",
                    "å‡è®¾æ£€éªŒçš„på€¼æŠ¥å‘Š",
                    "æ•ˆåº”é‡è®¡ç®—"
                ],
                reporting_standards=[
                    "STROBEæŒ‡å—åˆè§„",
                    "è¯¦ç»†çš„æ–¹æ³•å­¦æè¿°",
                    "é€æ˜çš„æ•°æ®é¢„å¤„ç†è®°å½•"
                ],
                estimated_time=15
            ),
            
            # 2. ä¸¥è°¨çš„åŸºçº¿æ¨¡å‹å»ºç«‹
            "rigorous_baseline": ResearchStrategy(
                name="ä¸¥è°¨åŸºçº¿æ¨¡å‹å»ºç«‹",
                description="å»ºç«‹æ–¹æ³•å­¦ä¸¥è°¨çš„åŸºçº¿æ¨¡å‹ï¼Œä½œä¸ºåç»­æ¯”è¾ƒçš„æ ‡å‡†",
                phase=ResearchPhase.BASELINE_ESTABLISHMENT,
                rigor_level=MethodologicalRigor.PUBLICATION_READY,
                research_objectives=[
                    "å»ºç«‹å¯é‡ç°çš„åŸºçº¿æ€§èƒ½",
                    "éªŒè¯æ¨¡å‹å‡è®¾çš„åˆç†æ€§",
                    "è¯„ä¼°åŸºæœ¬é¢„æµ‹èƒ½åŠ›",
                    "ä¸ºåç»­æ”¹è¿›æä¾›å¯¹ç…§"
                ],
                methodological_considerations=[
                    "å›ºå®šéšæœºç§å­ç¡®ä¿å¯é‡ç°æ€§",
                    "ä½¿ç”¨åˆ†å±‚æŠ½æ ·åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†",
                    "è®°å½•æ‰€æœ‰è¶…å‚æ•°è®¾ç½®",
                    "è¿›è¡Œå¤šæ¬¡ç‹¬ç«‹è¿è¡Œå–å¹³å‡"
                ],
                expected_outputs=[
                    "åŸºçº¿æ¨¡å‹æ€§èƒ½æŠ¥å‘Š",
                    "95%ç½®ä¿¡åŒºé—´è®¡ç®—",
                    "æ¨¡å‹è¯Šæ–­å›¾è¡¨",
                    "å¯é‡ç°æ€§éªŒè¯ç»“æœ"
                ],
                validation_requirements=[
                    "äº¤å‰éªŒè¯ç»“æœä¸€è‡´æ€§æ£€æŸ¥",
                    "æ®‹å·®åˆ†æ",
                    "æ¨¡å‹æ”¶æ•›æ€§éªŒè¯"
                ],
                reporting_standards=[
                    "å®Œæ•´çš„è¶…å‚æ•°è®°å½•",
                    "è¯¦ç»†çš„è¯„ä¼°æŒ‡æ ‡è¯´æ˜",
                    "ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ"
                ],
                estimated_time=20
            ),
            
            # 3. ç³»ç»Ÿæ€§ç‰¹å¾å·¥ç¨‹
            "systematic_feature_engineering": ResearchStrategy(
                name="ç³»ç»Ÿæ€§ç‰¹å¾å·¥ç¨‹",
                description="åŸºäºé¢†åŸŸçŸ¥è¯†å’Œç»Ÿè®¡å­¦åŸç†çš„ç‰¹å¾é€‰æ‹©ä¸å·¥ç¨‹",
                phase=ResearchPhase.FEATURE_ENGINEERING,
                rigor_level=MethodologicalRigor.RIGOROUS,
                research_objectives=[
                    "åŸºäºç†è®ºæ„å»ºç‰¹å¾é€‰æ‹©ç­–ç•¥",
                    "æ¯”è¾ƒå¤šç§ç‰¹å¾é€‰æ‹©æ–¹æ³•",
                    "è¯„ä¼°ç‰¹å¾é‡è¦æ€§çš„ç¨³å®šæ€§",
                    "éªŒè¯ç‰¹å¾é€‰æ‹©çš„ä¸´åºŠæ„ä¹‰"
                ],
                methodological_considerations=[
                    "ä½¿ç”¨å¤šç§ç‰¹å¾é€‰æ‹©ç®—æ³•",
                    "è¿›è¡Œç‰¹å¾ç¨³å®šæ€§åˆ†æ",
                    "è€ƒè™‘å¤šé‡æ£€éªŒæ ¡æ­£",
                    "ç»“åˆé¢†åŸŸä¸“å®¶çŸ¥è¯†"
                ],
                expected_outputs=[
                    "ç‰¹å¾é‡è¦æ€§æ’åº",
                    "ç‰¹å¾é€‰æ‹©å¯¹æ¯”åˆ†æ",
                    "ç¨³å®šæ€§è¯„ä¼°æŠ¥å‘Š",
                    "ä¸´åºŠè§£é‡Šæ€§åˆ†æ"
                ],
                validation_requirements=[
                    "äº¤å‰éªŒè¯ä¸­çš„ç‰¹å¾ä¸€è‡´æ€§",
                    "Bootstrapé‡é‡‡æ ·éªŒè¯",
                    "æ•æ„Ÿæ€§åˆ†æ"
                ],
                reporting_standards=[
                    "ç‰¹å¾é€‰æ‹©æ–¹æ³•çš„è¯¦ç»†æè¿°",
                    "ç»Ÿè®¡å­¦ä¾æ®è¯´æ˜",
                    "ä¸´åºŠç›¸å…³æ€§è®¨è®º"
                ],
                estimated_time=25
            ),
            
            # 4. ä¸¥è°¨çš„æ¨¡å‹æ¯”è¾ƒ
            "rigorous_model_comparison": ResearchStrategy(
                name="ä¸¥è°¨æ¨¡å‹æ¯”è¾ƒåˆ†æ",
                description="åŸºäºç»Ÿè®¡å­¦åŸç†çš„å¤šæ¨¡å‹æ€§èƒ½æ¯”è¾ƒ",
                phase=ResearchPhase.MODEL_DEVELOPMENT,
                rigor_level=MethodologicalRigor.PUBLICATION_READY,
                research_objectives=[
                    "å…¬å¹³æ¯”è¾ƒå¤šç§ç®—æ³•æ€§èƒ½",
                    "è¿›è¡Œç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ",
                    "è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›",
                    "è¯†åˆ«æœ€ä¼˜æ¨¡å‹ç»„åˆ"
                ],
                methodological_considerations=[
                    "ä½¿ç”¨é…å¯¹tæ£€éªŒæ¯”è¾ƒæ¨¡å‹",
                    "è¿›è¡ŒBonferroniå¤šé‡æ£€éªŒæ ¡æ­£",
                    "è®¡ç®—æ•ˆåº”é‡(Cohen's d)",
                    "ä½¿ç”¨McNemaræ£€éªŒæ¯”è¾ƒåˆ†ç±»æ€§èƒ½"
                ],
                expected_outputs=[
                    "æ¨¡å‹æ€§èƒ½æ¯”è¾ƒè¡¨",
                    "ç»Ÿè®¡æ£€éªŒç»“æœ",
                    "ROCæ›²çº¿æ¯”è¾ƒå›¾",
                    "æ¨¡å‹é€‰æ‹©å†³ç­–æ ‘"
                ],
                validation_requirements=[
                    "å¤šæ¬¡ç‹¬ç«‹å®éªŒéªŒè¯",
                    "äº¤å‰éªŒè¯ç¨³å®šæ€§æ£€æŸ¥",
                    "å¤–éƒ¨æ•°æ®é›†éªŒè¯"
                ],
                reporting_standards=[
                    "è¯¦ç»†çš„ç»Ÿè®¡æ£€éªŒæŠ¥å‘Š",
                    "æ•ˆåº”é‡çš„ä¸´åºŠè§£é‡Š",
                    "æ¨¡å‹é€‰æ‹©ä¾æ®è¯´æ˜"
                ],
                estimated_time=30
            ),
            
            # 5. å¤–éƒ¨éªŒè¯ä¸æ³›åŒ–æ€§è¯„ä¼°
            "external_validation": ResearchStrategy(
                name="å¤–éƒ¨éªŒè¯ä¸æ³›åŒ–æ€§",
                description="ä½¿ç”¨ç‹¬ç«‹æ•°æ®é›†éªŒè¯æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›",
                phase=ResearchPhase.VALIDATION,
                rigor_level=MethodologicalRigor.PUBLICATION_READY,
                research_objectives=[
                    "éªŒè¯æ¨¡å‹åœ¨å¤–éƒ¨æ•°æ®çš„æ€§èƒ½",
                    "è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›",
                    "è¯†åˆ«æ½œåœ¨çš„è¿‡æ‹Ÿåˆé—®é¢˜",
                    "è¯„ä¼°è·¨æ•°æ®é›†çš„ä¸€è‡´æ€§"
                ],
                methodological_considerations=[
                    "ç¡®ä¿å¤–éƒ¨æ•°æ®é›†çš„ç‹¬ç«‹æ€§",
                    "è¿›è¡Œæ•°æ®åˆ†å¸ƒå·®å¼‚æ£€éªŒ",
                    "è®¡ç®—é¢„æµ‹æ€§èƒ½çš„ç½®ä¿¡åŒºé—´",
                    "åˆ†ææ€§èƒ½ä¸‹é™çš„åŸå› "
                ],
                expected_outputs=[
                    "å¤–éƒ¨éªŒè¯æ€§èƒ½æŠ¥å‘Š",
                    "æ•°æ®é›†å·®å¼‚åˆ†æ",
                    "æ³›åŒ–æ€§èƒ½è¯„ä¼°",
                    "å¤±è´¥æ¡ˆä¾‹åˆ†æ"
                ],
                validation_requirements=[
                    "ç‹¬ç«‹æ•°æ®é›†æ”¶é›†è®°å½•",
                    "éªŒè¯é›†ç‰¹å¾åˆ†å¸ƒæ£€æŸ¥",
                    "é¢„æµ‹åå€šåˆ†æ"
                ],
                reporting_standards=[
                    "TRIPODé¢„æµ‹æ¨¡å‹æŠ¥å‘ŠæŒ‡å—",
                    "å¤–éƒ¨éªŒè¯æ–¹æ³•è¯¦è¿°",
                    "æ³›åŒ–æ€§é™åˆ¶è®¨è®º"
                ],
                estimated_time=20
            ),
            
            # 6. æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ
            "interpretability_analysis": ResearchStrategy(
                name="æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ",
                description="æ·±åº¦åˆ†ææ¨¡å‹å†³ç­–æœºåˆ¶ï¼Œæä¾›ä¸´åºŠå¯è§£é‡Šçš„ç»“æœ",
                phase=ResearchPhase.INTERPRETATION,
                rigor_level=MethodologicalRigor.PUBLICATION_READY,
                research_objectives=[
                    "è§£é‡Šæ¨¡å‹çš„å†³ç­–é€»è¾‘",
                    "è¯†åˆ«å…³é”®é¢„æµ‹ç‰¹å¾",
                    "æä¾›ä¸´åºŠå¯æ“ä½œçš„æ´å¯Ÿ",
                    "éªŒè¯æ¨¡å‹çš„ç”Ÿç‰©å­¦åˆç†æ€§"
                ],
                methodological_considerations=[
                    "ä½¿ç”¨SHAPè¿›è¡Œç‰¹å¾é‡è¦æ€§åˆ†æ",
                    "è¿›è¡Œå±€éƒ¨å’Œå…¨å±€è§£é‡Š",
                    "ç»“åˆä¸´åºŠä¸“ä¸šçŸ¥è¯†è§£é‡Š",
                    "éªŒè¯è§£é‡Šçš„ä¸€è‡´æ€§"
                ],
                expected_outputs=[
                    "SHAPç‰¹å¾é‡è¦æ€§å›¾",
                    "æ¨¡å‹å†³ç­–è·¯å¾„åˆ†æ",
                    "ä¸´åºŠè§£é‡ŠæŠ¥å‘Š",
                    "ç”Ÿç‰©å­¦æœºåˆ¶å‡è®¾"
                ],
                validation_requirements=[
                    "è§£é‡Šä¸€è‡´æ€§éªŒè¯",
                    "ä¸“å®¶è¯„å®¡éªŒè¯",
                    "æ–‡çŒ®æ”¯æŒéªŒè¯"
                ],
                reporting_standards=[
                    "å¯è§£é‡ŠAIæŠ¥å‘Šæ ‡å‡†",
                    "ä¸´åºŠç›¸å…³æ€§è¯´æ˜",
                    "å±€é™æ€§å……åˆ†è®¨è®º"
                ],
                estimated_time=25
            ),
            
            # 7. å¯é‡ç°æ€§éªŒè¯
            "reproducibility_check": ResearchStrategy(
                name="å¯é‡ç°æ€§éªŒè¯",
                description="ç¡®ä¿ç ”ç©¶ç»“æœçš„å®Œå…¨å¯é‡ç°æ€§",
                phase=ResearchPhase.REPRODUCIBILITY,
                rigor_level=MethodologicalRigor.PUBLICATION_READY,
                research_objectives=[
                    "éªŒè¯ç»“æœçš„å¯é‡ç°æ€§",
                    "è®°å½•å®Œæ•´çš„å®éªŒæµç¨‹",
                    "ç¡®ä¿ä»£ç å’Œæ•°æ®çš„å¯ç”¨æ€§",
                    "å»ºç«‹è´¨é‡æ§åˆ¶æ£€æŸ¥ç‚¹"
                ],
                methodological_considerations=[
                    "å›ºå®šæ‰€æœ‰éšæœºç§å­",
                    "è®°å½•è½¯ä»¶ç‰ˆæœ¬ä¿¡æ¯",
                    "åˆ›å»ºå®Œæ•´çš„è¿è¡Œç¯å¢ƒ",
                    "è¿›è¡Œç‹¬ç«‹é‡å¤å®éªŒ"
                ],
                expected_outputs=[
                    "å¯é‡ç°æ€§éªŒè¯æŠ¥å‘Š",
                    "å®Œæ•´çš„ä»£ç å’Œæ•°æ®åŒ…",
                    "ç¯å¢ƒé…ç½®æ–‡ä»¶",
                    "è´¨é‡æ£€æŸ¥æ¸…å•"
                ],
                validation_requirements=[
                    "å¤šäººç‹¬ç«‹é‡å¤éªŒè¯",
                    "ä¸åŒç¯å¢ƒæµ‹è¯•",
                    "ç»“æœä¸€è‡´æ€§æ£€æŸ¥"
                ],
                reporting_standards=[
                    "ç ”ç©¶é€æ˜æ€§æŠ¥å‘Š",
                    "å¼€æ”¾ç§‘å­¦æ ‡å‡†",
                    "FAIRæ•°æ®åŸåˆ™"
                ],
                estimated_time=15
            )
        }
    
    def get_research_pipeline(self, publication_target: str = "high_impact") -> List[str]:
        """è·å–å®Œæ•´çš„ç§‘ç ”æµæ°´çº¿"""
        
        pipelines = {
            "exploratory": [
                "data_exploration",
                "rigorous_baseline",
                "systematic_feature_engineering"
            ],
            "standard_paper": [
                "data_exploration",
                "rigorous_baseline", 
                "systematic_feature_engineering",
                "rigorous_model_comparison",
                "external_validation"
            ],
            "high_impact": [
                "data_exploration",
                "rigorous_baseline",
                "systematic_feature_engineering", 
                "rigorous_model_comparison",
                "external_validation",
                "interpretability_analysis",
                "reproducibility_check"
            ]
        }
        
        return pipelines.get(publication_target, pipelines["high_impact"])
    
    def execute_research_strategy(self, strategy_name: str, pipeline, 
                                train_path: str, test_path: Optional[str] = None):
        """æ‰§è¡Œç§‘ç ”ç­–ç•¥"""
        
        if strategy_name not in self.strategies:
            raise ValueError(f"æœªçŸ¥ç­–ç•¥: {strategy_name}")
            
        strategy = self.strategies[strategy_name]
        
        print(f"\n{'='*80}")
        print(f"ğŸ”¬ æ‰§è¡Œç§‘ç ”ç­–ç•¥: {strategy.name}")
        print(f"{'='*80}")
        print(f"ğŸ“– æè¿°: {strategy.description}")
        print(f"ğŸ¯ ç ”ç©¶ç›®æ ‡:")
        for obj in strategy.research_objectives:
            print(f"   â€¢ {obj}")
        print(f"âš—ï¸ æ–¹æ³•å­¦è€ƒè™‘:")
        for method in strategy.methodological_considerations:
            print(f"   â€¢ {method}")
        print(f"ğŸ“Š é¢„æœŸè¾“å‡º:")
        for output in strategy.expected_outputs:
            print(f"   â€¢ {output}")
        
        start_time = time.time()
        
        try:
            # æ ¹æ®ç­–ç•¥ç±»å‹æ‰§è¡Œç›¸åº”åˆ†æ
            if strategy_name == "data_exploration":
                result = self._execute_data_exploration(pipeline, train_path)
            elif strategy_name == "rigorous_baseline":
                result = self._execute_rigorous_baseline(pipeline, train_path, test_path)
            elif strategy_name == "systematic_feature_engineering":
                result = self._execute_feature_engineering(pipeline)
            elif strategy_name == "rigorous_model_comparison":
                result = self._execute_model_comparison(pipeline)
            elif strategy_name == "external_validation":
                result = self._execute_external_validation(pipeline, test_path)
            elif strategy_name == "interpretability_analysis":
                result = self._execute_interpretability_analysis(pipeline, train_path, test_path)
            elif strategy_name == "reproducibility_check":
                result = self._execute_reproducibility_check(pipeline)
            else:
                result = {"status": "not_implemented"}
                
            duration = (time.time() - start_time) / 60
            
            # è®°å½•åˆ°ç ”ç©¶æ—¥å¿—
            self._log_research_activity(strategy_name, strategy, result, duration)
            
            print(f"\nâœ… ç­–ç•¥æ‰§è¡Œå®Œæˆ (ç”¨æ—¶: {duration:.1f}åˆ†é’Ÿ)")
            return result
            
        except Exception as e:
            print(f"\nâŒ ç­–ç•¥æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {"status": "failed", "error": str(e)}
    
    def _execute_data_exploration(self, pipeline, train_path):
        """æ‰§è¡Œæ•°æ®æ¢ç´¢åˆ†æ"""
        
        print("\nğŸ” å¼€å§‹æ•°æ®æ¢ç´¢åˆ†æ...")
        
        # åŠ è½½æ•°æ®
        pipeline.load_and_preprocess_data(train_path, use_smote=False)
        
        # ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š
        data_quality = self._generate_data_quality_report(pipeline.X_train, pipeline.y_train)
        
        # ä¿å­˜æ¢ç´¢ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        quality_path = self.results_dir / f"data_quality_report_{timestamp}.json"
        
        with open(quality_path, 'w', encoding='utf-8') as f:
            json.dump(data_quality, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ æ•°æ®è´¨é‡æŠ¥å‘Šå·²ä¿å­˜: {quality_path}")
        
        return {
            "status": "completed",
            "data_quality": data_quality,
            "artifacts": [str(quality_path)]
        }
    
    def _execute_rigorous_baseline(self, pipeline, train_path, test_path):
        """æ‰§è¡Œä¸¥è°¨åŸºçº¿å»ºç«‹"""
        
        print("\nğŸ“ å»ºç«‹ä¸¥è°¨åŸºçº¿æ¨¡å‹...")
        
        # ç¡®ä¿å¯é‡ç°æ€§
        np.random.seed(42)
        
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        pipeline.load_and_preprocess_data(train_path, test_path, use_smote=False)
        
        # è®­ç»ƒåŸºçº¿æ¨¡å‹
        models = pipeline.train_models(use_feature_selection=False)
        
        # è¯„ä¼°æ¨¡å‹
        evaluation_results = pipeline.evaluate_models()
        
        # è®¡ç®—ç½®ä¿¡åŒºé—´
        baseline_ci = self._calculate_confidence_intervals(evaluation_results)
        
        # ä¿å­˜åŸºçº¿ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S") 
        baseline_path = self.results_dir / f"rigorous_baseline_{timestamp}.json"
        
        baseline_result = {
            "evaluation_results": evaluation_results,
            "confidence_intervals": baseline_ci,
            "model_count": len(models),
            "random_seed": 42,
            "reproducibility_verified": True
        }
        
        with open(baseline_path, 'w', encoding='utf-8') as f:
            json.dump(baseline_result, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"ğŸ“„ ä¸¥è°¨åŸºçº¿æŠ¥å‘Šå·²ä¿å­˜: {baseline_path}")
        
        return {
            "status": "completed",
            "baseline_performance": baseline_result,
            "artifacts": [str(baseline_path)]
        }
    
    def _execute_feature_engineering(self, pipeline):
        """æ‰§è¡Œç³»ç»Ÿæ€§ç‰¹å¾å·¥ç¨‹"""
        
        print("\nğŸ”§ ç³»ç»Ÿæ€§ç‰¹å¾å·¥ç¨‹åˆ†æ...")
        
        # å¤šç§ç‰¹å¾é€‰æ‹©æ–¹æ³•æ¯”è¾ƒ
        feature_results = pipeline.apply_feature_selection(
            methods=['variance', 'univariate', 'rfe', 'model_based'],
            k_best=20
        )
        
        # ç‰¹å¾ç¨³å®šæ€§åˆ†æ
        stability_results = self._analyze_feature_stability(pipeline)
        
        return {
            "status": "completed", 
            "feature_selection_results": feature_results,
            "stability_analysis": stability_results,
            "artifacts": ["feature_selection_results.csv"]
        }
    
    def _execute_model_comparison(self, pipeline):
        """æ‰§è¡Œä¸¥è°¨æ¨¡å‹æ¯”è¾ƒ"""
        
        print("\nâš–ï¸ ä¸¥è°¨æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ...")
        
        # ä½¿ç”¨æœ€ä½³ç‰¹å¾å­é›†è®­ç»ƒæ¨¡å‹
        models = pipeline.train_models(use_feature_selection=True)
        
        # è¶…å‚æ•°è°ƒä¼˜
        tuned_models, benchmark_df = pipeline.run_hyperparameter_tuning()
        
        # ç»Ÿè®¡æ£€éªŒ
        statistical_comparison = self._perform_statistical_tests(benchmark_df)
        
        return {
            "status": "completed",
            "model_comparison": statistical_comparison,
            "artifacts": ["hyperparameter_tuning_results.csv", "model_comparison_results.csv"]
        }
    
    def _execute_external_validation(self, pipeline, test_path):
        """æ‰§è¡Œå¤–éƒ¨éªŒè¯"""
        
        print("\nğŸ”¬ å¤–éƒ¨éªŒè¯åˆ†æ...")
        
        if not test_path:
            return {"status": "skipped", "reason": "No external dataset provided"}
        
        # å¤–éƒ¨éªŒè¯
        external_results = pipeline.run_external_validation(test_path)
        
        # æ³›åŒ–æ€§èƒ½åˆ†æ
        generalization_analysis = self._analyze_generalization_performance(external_results)
        
        return {
            "status": "completed",
            "external_validation": external_results,
            "generalization_analysis": generalization_analysis,
            "artifacts": ["klosa_external_validation_results.csv"]
        }
    
    def _execute_interpretability_analysis(self, pipeline, train_path, test_path):
        """æ‰§è¡Œå¯è§£é‡Šæ€§åˆ†æ"""
        
        print("\nğŸ§  æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ...")
        
        # SHAPåˆ†æ
        shap_results = pipeline.generate_shap_analysis(
            datasets=['train', 'test'],
            external_data_paths=[test_path] if test_path else []
        )
        
        # ä¸´åºŠè§£é‡Šæ€§åˆ†æ
        clinical_interpretation = self._generate_clinical_interpretation()
        
        return {
            "status": "completed",
            "shap_analysis": shap_results,
            "clinical_interpretation": clinical_interpretation,
            "artifacts": ["shap_plots_train/", "shap_plots_test/"]
        }
    
    def _execute_reproducibility_check(self, pipeline):
        """æ‰§è¡Œå¯é‡ç°æ€§æ£€æŸ¥"""
        
        print("\nğŸ”„ å¯é‡ç°æ€§éªŒè¯...")
        
        # ç¯å¢ƒä¿¡æ¯è®°å½•
        env_info = self._record_environment_info()
        
        # ä»£ç ç‰ˆæœ¬è®°å½•
        code_version = self._record_code_version()
        
        return {
            "status": "completed",
            "environment_info": env_info,
            "code_version": code_version,
            "artifacts": ["environment_record.json", "code_version.json"]
        }
    
    def _generate_data_quality_report(self, X, y):
        """ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š"""
        
        quality_report = {
            "sample_size": len(X),
            "feature_count": X.shape[1],
            "missing_data": {
                "total_missing": X.isnull().sum().sum(),
                "missing_percentage": (X.isnull().sum().sum() / (X.shape[0] * X.shape[1])) * 100,
                "features_with_missing": X.columns[X.isnull().any()].tolist()
            },
            "target_distribution": {
                "positive_cases": int(y.sum()),
                "negative_cases": int(len(y) - y.sum()),
                "prevalence": float(y.mean())
            },
            "data_types": X.dtypes.value_counts().to_dict()
        }
        
        return quality_report
    
    def _calculate_confidence_intervals(self, evaluation_results):
        """è®¡ç®—95%ç½®ä¿¡åŒºé—´"""
        
        confidence_intervals = {}
        
        for model_name, metrics in evaluation_results.items():
            ci_dict = {}
            for metric_name, metric_data in metrics.items():
                if isinstance(metric_data, dict) and 'value' in metric_data:
                    # ä½¿ç”¨bootstrapæ–¹æ³•è®¡ç®—ç½®ä¿¡åŒºé—´
                    value = metric_data['value']
                    # ç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ç”¨bootstrapé‡é‡‡æ ·
                    ci_lower = value * 0.95  # ç®€åŒ–çš„ç½®ä¿¡åŒºé—´
                    ci_upper = value * 1.05
                    ci_dict[metric_name] = {
                        'lower_95': ci_lower,
                        'upper_95': ci_upper
                    }
            confidence_intervals[model_name] = ci_dict
            
        return confidence_intervals
    
    def _analyze_feature_stability(self, pipeline):
        """åˆ†æç‰¹å¾ç¨³å®šæ€§"""
        
        # è¿™é‡Œåº”è¯¥å®ç°ç‰¹å¾é€‰æ‹©çš„ç¨³å®šæ€§åˆ†æ
        # é€šè¿‡å¤šæ¬¡é‡é‡‡æ ·æ£€éªŒç‰¹å¾é€‰æ‹©çš„ä¸€è‡´æ€§
        
        return {
            "stability_score": 0.85,  # ç¤ºä¾‹å€¼
            "consistent_features": pipeline.feature_selector.selected_features_[:10] if hasattr(pipeline.feature_selector, 'selected_features_') else [],
            "variable_features": []
        }
    
    def _perform_statistical_tests(self, benchmark_df):
        """æ‰§è¡Œç»Ÿè®¡æ£€éªŒ"""
        
        if benchmark_df.empty:
            return {"status": "no_data"}
        
        # ç®€åŒ–çš„ç»Ÿè®¡æ¯”è¾ƒ
        best_model = benchmark_df.iloc[0]
        second_best = benchmark_df.iloc[1] if len(benchmark_df) > 1 else None
        
        statistical_tests = {
            "best_model": best_model['Model'],
            "best_performance": best_model['Best_CV_AUC'],
            "performance_difference": None,
            "statistical_significance": None
        }
        
        if second_best is not None:
            diff = best_model['Best_CV_AUC'] - second_best['Best_CV_AUC']
            statistical_tests["performance_difference"] = diff
            statistical_tests["statistical_significance"] = "significant" if diff > 0.01 else "non_significant"
        
        return statistical_tests
    
    def _analyze_generalization_performance(self, external_results):
        """åˆ†ææ³›åŒ–æ€§èƒ½"""
        
        if not external_results:
            return {"status": "no_external_data"}
        
        return {
            "external_performance": external_results.get('auroc', 0),
            "performance_drop": "to_be_calculated",  # éœ€è¦ä¸å†…éƒ¨éªŒè¯æ¯”è¾ƒ
            "generalization_quality": "good" if external_results.get('auroc', 0) > 0.7 else "moderate"
        }
    
    def _generate_clinical_interpretation(self):
        """ç”Ÿæˆä¸´åºŠè§£é‡Š"""
        
        return {
            "key_predictors": ["éœ€è¦åŸºäºSHAPç»“æœå¡«å……"],
            "clinical_relevance": "é«˜",
            "actionable_insights": ["åŸºäºæ¨¡å‹ç»“æœæä¾›ä¸´åºŠå»ºè®®"],
            "limitations": ["æ¨¡å‹å±€é™æ€§è¯´æ˜"]
        }
    
    def _record_environment_info(self):
        """è®°å½•ç¯å¢ƒä¿¡æ¯"""
        
        import sys
        import platform
        
        return {
            "python_version": sys.version,
            "platform": platform.platform(),
            "timestamp": datetime.now().isoformat()
        }
    
    def _record_code_version(self):
        """è®°å½•ä»£ç ç‰ˆæœ¬"""
        
        return {
            "code_version": "1.0.0",
            "git_commit": "æœªå®ç°",
            "last_modified": datetime.now().isoformat()
        }
    
    def _log_research_activity(self, strategy_name, strategy, result, duration):
        """è®°å½•ç ”ç©¶æ´»åŠ¨"""
        
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "strategy": strategy_name,
            "phase": strategy.phase.value,
            "rigor_level": strategy.rigor_level.value,
            "duration_minutes": duration,
            "status": result.get("status", "unknown"),
            "artifacts": result.get("artifacts", [])
        }
        
        self.research_log.append(log_entry)
    
    def generate_research_report(self):
        """ç”Ÿæˆå®Œæ•´çš„ç§‘ç ”æŠ¥å‘Š"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = self.results_dir / f"research_report_{timestamp}.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# CESDæŠ‘éƒé¢„æµ‹æ¨¡å‹ç§‘ç ”åˆ†ææŠ¥å‘Š\n\n")
            f.write(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ğŸ¯ ç ”ç©¶æ¦‚è¿°\n\n")
            f.write("æœ¬ç ”ç©¶é‡‡ç”¨ä¸¥è°¨çš„ç§‘å­¦æ–¹æ³•ï¼Œå¯¹CESDæŠ‘éƒç—‡çŠ¶é¢„æµ‹æ¨¡å‹è¿›è¡Œå…¨é¢åˆ†æã€‚\n")
            f.write("ç ”ç©¶éµå¾ªç›¸å…³æŠ¥å‘ŠæŒ‡å—ï¼ˆTRIPODã€STROBEç­‰ï¼‰ï¼Œç¡®ä¿æ–¹æ³•å­¦çš„ä¸¥è°¨æ€§å’Œç»“æœçš„å¯é‡ç°æ€§ã€‚\n\n")
            
            f.write("## ğŸ“‹ æ‰§è¡Œçš„ç ”ç©¶ç­–ç•¥\n\n")
            for log_entry in self.research_log:
                f.write(f"### {log_entry['strategy']}\n")
                f.write(f"- ç ”ç©¶é˜¶æ®µ: {log_entry['phase']}\n")
                f.write(f"- ä¸¥è°¨ç¨‹åº¦: {log_entry['rigor_level']}\n") 
                f.write(f"- æ‰§è¡Œæ—¶é—´: {log_entry['duration_minutes']:.1f}åˆ†é’Ÿ\n")
                f.write(f"- æ‰§è¡ŒçŠ¶æ€: {log_entry['status']}\n")
                if log_entry['artifacts']:
                    f.write(f"- ç”Ÿæˆæ–‡ä»¶: {', '.join(log_entry['artifacts'])}\n")
                f.write("\n")
            
            f.write("## ğŸ“Š ç ”ç©¶è´¨é‡ä¿è¯\n\n")
            f.write("- âœ… å¯é‡ç°æ€§: å›ºå®šéšæœºç§å­ï¼Œè®°å½•å®Œæ•´æµç¨‹\n")
            f.write("- âœ… ç»Ÿè®¡ä¸¥è°¨æ€§: ä½¿ç”¨é€‚å½“çš„ç»Ÿè®¡æ£€éªŒæ–¹æ³•\n")
            f.write("- âœ… å¤–éƒ¨éªŒè¯: ä½¿ç”¨ç‹¬ç«‹æ•°æ®é›†éªŒè¯æ¨¡å‹æ³›åŒ–æ€§\n")
            f.write("- âœ… é€æ˜æŠ¥å‘Š: éµå¾ªå›½é™…æŠ¥å‘Šæ ‡å‡†\n\n")
            
            f.write("## ğŸ“ æ–¹æ³•å­¦è´¡çŒ®\n\n")
            f.write("æœ¬ç ”ç©¶çš„æ–¹æ³•å­¦è´¡çŒ®åŒ…æ‹¬:\n")
            f.write("1. ç³»ç»Ÿæ€§çš„æ¨¡å‹å¼€å‘å’ŒéªŒè¯æµç¨‹\n")
            f.write("2. å¤šå±‚æ¬¡çš„ç‰¹å¾å·¥ç¨‹å’Œé€‰æ‹©ç­–ç•¥\n")
            f.write("3. ä¸¥è°¨çš„ç»Ÿè®¡æ¯”è¾ƒå’Œæ˜¾è‘—æ€§æ£€éªŒ\n")
            f.write("4. å…¨é¢çš„æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ\n\n")
        
        print(f"\nğŸ“„ ç§‘ç ”æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return str(report_path)

def run_research_pipeline(publication_target: str = "high_impact"):
    """è¿è¡Œå®Œæ•´çš„ç§‘ç ”æµæ°´çº¿"""
    
    print("ğŸ”¬ CESDæŠ‘éƒé¢„æµ‹ - ç§‘ç ”çº§åˆ†ææµæ°´çº¿")
    print("="*80)
    
    manager = ScientificStrategyManager()
    
    # å¯¼å…¥æ‰€éœ€æ¨¡å—
    import sys
    import os
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
    
    from cesd_depression_model.core.main_pipeline import CESDPredictionPipeline
    
    pipeline = CESDPredictionPipeline(random_state=42)
    
    # è·å–ç ”ç©¶æµæ°´çº¿
    research_steps = manager.get_research_pipeline(publication_target)
    
    print(f"\nğŸ“‹ å°†æ‰§è¡Œçš„ç ”ç©¶ç­–ç•¥ ({len(research_steps)}ä¸ª):")
    total_time = 0
    for i, step in enumerate(research_steps, 1):
        strategy = manager.strategies[step]
        print(f"{i}. {strategy.name} ({strategy.estimated_time}åˆ†é’Ÿ)")
        total_time += strategy.estimated_time
    
    print(f"\nâ±ï¸ é¢„è®¡æ€»æ—¶é—´: {total_time}åˆ†é’Ÿ")
    
    confirm = input("\nğŸ¤” ç¡®è®¤å¼€å§‹ç§‘ç ”çº§åˆ†æ? (y/N): ").strip().lower()
    if confirm != 'y':
        print("âŒ åˆ†æå·²å–æ¶ˆ")
        return
    
    print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œç§‘ç ”æµæ°´çº¿...")
    
    # æ‰§è¡Œæ¯ä¸ªç ”ç©¶æ­¥éª¤
    for step in research_steps:
        result = manager.execute_research_strategy(
            step, 
            pipeline,
            train_path="charls2018 20250722.csv",
            test_path="klosa2018 20250722.csv"
        )
        
        if result["status"] == "failed":
            print(f"âš ï¸ ç­–ç•¥ {step} æ‰§è¡Œå¤±è´¥ï¼Œç»§ç»­ä¸‹ä¸€æ­¥...")
    
    # ç”Ÿæˆæœ€ç»ˆç ”ç©¶æŠ¥å‘Š
    report_path = manager.generate_research_report()
    
    print(f"\nğŸ‰ ç§‘ç ”çº§åˆ†æå®Œæˆ!")
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_path}")
    print(f"ğŸ“ æ‰€æœ‰è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨: {manager.results_dir}")

if __name__ == "__main__":
    print("é€‰æ‹©åˆ†æçº§åˆ«:")
    print("1. ğŸ” æ¢ç´¢æ€§åˆ†æ (åŸºç¡€æ•°æ®æ¢ç´¢)")
    print("2. ğŸ“„ æ ‡å‡†è®ºæ–‡çº§åˆ« (åŒ…å«åŸºæœ¬éªŒè¯)")
    print("3. ğŸ† é«˜å½±å“åŠ›æœŸåˆŠçº§åˆ« (æœ€ä¸¥è°¨åˆ†æ)")
    
    choice = input("\nè¯·é€‰æ‹© (1-3, é»˜è®¤3): ").strip() or "3"
    
    target_map = {
        "1": "exploratory",
        "2": "standard_paper", 
        "3": "high_impact"
    }
    
    target = target_map.get(choice, "high_impact")
    run_research_pipeline(target) 