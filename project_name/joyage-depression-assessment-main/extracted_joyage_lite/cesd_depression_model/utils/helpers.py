"""
Utility functions for CESD Depression Prediction Model
"""

import os
import json
import joblib
import pandas as pd
import numpy as np
from datetime import datetime
from ..config import FILE_PATHS

def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    for dir_name in FILE_PATHS.values():
        os.makedirs(dir_name, exist_ok=True)
        
def save_model(model, filename, model_dir=None):
    """ä¿å­˜æ¨¡å‹"""
    if model_dir is None:
        model_dir = FILE_PATHS['model_save_dir']
        
    os.makedirs(model_dir, exist_ok=True)
    
    filepath = os.path.join(model_dir, filename)
    joblib.dump(model, filepath)
    print(f"âœ“ æ¨¡å‹å·²ä¿å­˜: {filepath}")
    
def load_model(filename, model_dir=None):
    """åŠ è½½æ¨¡å‹"""
    if model_dir is None:
        model_dir = FILE_PATHS['model_save_dir']
        
    filepath = os.path.join(model_dir, filename)
    if os.path.exists(filepath):
        model = joblib.load(filepath)
        print(f"âœ“ æ¨¡å‹å·²åŠ è½½: {filepath}")
        return model
    else:
        print(f"âœ— æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return None
        
def save_results(results, filename, results_dir=None):
    """ä¿å­˜ç»“æœ"""
    if results_dir is None:
        results_dir = FILE_PATHS['results_dir']
        
    os.makedirs(results_dir, exist_ok=True)
    
    filepath = os.path.join(results_dir, filename)
    
    # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©ä¿å­˜æ ¼å¼
    if filename.endswith('.json'):
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    elif filename.endswith('.csv'):
        if isinstance(results, pd.DataFrame):
            results.to_csv(filepath, index=False, encoding='utf-8-sig')
        else:
            pd.DataFrame(results).to_csv(filepath, index=False, encoding='utf-8-sig')
    else:
        # é»˜è®¤ä½¿ç”¨joblibä¿å­˜
        joblib.dump(results, filepath)
        
    print(f"âœ“ ç»“æœå·²ä¿å­˜: {filepath}")
    
def load_results(filename, results_dir=None):
    """åŠ è½½ç»“æœ"""
    if results_dir is None:
        results_dir = FILE_PATHS['results_dir']
        
    filepath = os.path.join(results_dir, filename)
    
    if not os.path.exists(filepath):
        print(f"âœ— ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return None
        
    # æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©åŠ è½½æ ¼å¼
    if filename.endswith('.json'):
        with open(filepath, 'r', encoding='utf-8') as f:
            results = json.load(f)
    elif filename.endswith('.csv'):
        results = pd.read_csv(filepath)
    else:
        results = joblib.load(filepath)
        
    print(f"âœ“ ç»“æœå·²åŠ è½½: {filepath}")
    return results
    
def generate_timestamp():
    """ç”Ÿæˆæ—¶é—´æˆ³"""
    return datetime.now().strftime("%Y%m%d_%H%M%S")
    
def validate_data(X, y):
    """éªŒè¯æ•°æ®"""
    # æ£€æŸ¥å½¢çŠ¶åŒ¹é…
    if len(X) != len(y):
        raise ValueError(f"Xå’Œyçš„æ ·æœ¬æ•°ä¸åŒ¹é…: {len(X)} vs {len(y)}")
        
    # æ£€æŸ¥ç¼ºå¤±å€¼
    if hasattr(X, 'isnull'):
        null_count = X.isnull().sum().sum()
        if null_count > 0:
            print(f"âš ï¸ Xä¸­æœ‰ {null_count} ä¸ªç¼ºå¤±å€¼")
            
    if hasattr(y, 'isnull'):
        null_count = y.isnull().sum()
        if null_count > 0:
            print(f"âš ï¸ yä¸­æœ‰ {null_count} ä¸ªç¼ºå¤±å€¼")
            
    # æ£€æŸ¥ç›®æ ‡å˜é‡åˆ†å¸ƒ
    unique_vals = np.unique(y)
    print(f"ç›®æ ‡å˜é‡ç±»åˆ«: {unique_vals}")
    
    if len(unique_vals) < 2:
        raise ValueError("ç›®æ ‡å˜é‡åªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œæ— æ³•è¿›è¡Œåˆ†ç±»")
        
    return True
    
def calculate_class_weights(y):
    """è®¡ç®—ç±»åˆ«æƒé‡"""
    from sklearn.utils.class_weight import compute_class_weight
    
    classes = np.unique(y)
    weights = compute_class_weight('balanced', classes=classes, y=y)
    
    class_weight_dict = dict(zip(classes, weights))
    print(f"ç±»åˆ«æƒé‡: {class_weight_dict}")
    
    return class_weight_dict
    
def format_results_table(results):
    """æ ¼å¼åŒ–ç»“æœè¡¨æ ¼"""
    formatted_data = []
    
    for model_name, metrics in results.items():
        row = {'Model': model_name}
        
        for metric_name, metric_data in metrics.items():
            if isinstance(metric_data, dict) and 'value' in metric_data:
                # å¸¦ç½®ä¿¡åŒºé—´çš„æ ¼å¼
                value = metric_data['value']
                ci_lower = metric_data['ci_lower']
                ci_upper = metric_data['ci_upper']
                row[metric_name] = f"{value:.3f} ({ci_lower:.3f}-{ci_upper:.3f})"
            else:
                # ç®€å•æ•°å€¼æ ¼å¼
                row[metric_name] = f"{metric_data:.3f}"
                
        formatted_data.append(row)
        
    return pd.DataFrame(formatted_data)
    
def print_summary(results):
    """æ‰“å°ç»“æœæ‘˜è¦"""
    print(f"\n{'='*60}")
    print("æ¨¡å‹æ€§èƒ½æ‘˜è¦")
    print(f"{'='*60}")
    
    # æ‰¾åˆ°æœ€ä½³æ¨¡å‹
    best_model = None
    best_auroc = -1
    
    for model_name, metrics in results.items():
        auroc = metrics.get('AUROC', {})
        if isinstance(auroc, dict):
            auroc_value = auroc.get('value', 0)
        else:
            auroc_value = auroc
            
        if auroc_value > best_auroc:
            best_auroc = auroc_value
            best_model = model_name
            
    print(f"ğŸ† æœ€ä½³æ¨¡å‹: {best_model} (AUROC: {best_auroc:.3f})")
    
    # æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹çš„ä¸»è¦æŒ‡æ ‡
    print(f"\næ‰€æœ‰æ¨¡å‹æ€§èƒ½:")
    print("-" * 60)
    print(f"{'Model':<15} {'AUROC':<8} {'AUPRC':<8} {'F1':<8} {'Accuracy':<8}")
    print("-" * 60)
    
    for model_name, metrics in results.items():
        auroc = metrics.get('AUROC', {})
        auprc = metrics.get('AUPRC', {})
        f1 = metrics.get('F1_Score', {})
        accuracy = metrics.get('Accuracy', {})
        
        # æå–æ•°å€¼
        if isinstance(auroc, dict):
            auroc_val = auroc.get('value', 0.0)
        else:
            auroc_val = float(auroc) if auroc is not None else 0.0
            
        if isinstance(auprc, dict):
            auprc_val = auprc.get('value', 0.0)
        else:
            auprc_val = float(auprc) if auprc is not None else 0.0
            
        if isinstance(f1, dict):
            f1_val = f1.get('value', 0.0)
        else:
            f1_val = float(f1) if f1 is not None else 0.0
            
        if isinstance(accuracy, dict):
            accuracy_val = accuracy.get('value', 0.0)
        else:
            accuracy_val = float(accuracy) if accuracy is not None else 0.0
        
        try:
            print(f"{model_name:<15} {auroc_val:<8.3f} {auprc_val:<8.3f} {f1_val:<8.3f} {accuracy_val:<8.3f}")
        except Exception as e:
            print(f"{model_name} - æ ¼å¼åŒ–é”™è¯¯: {str(e)}")
            print(f"åŸå§‹å€¼: AUROC={auroc}, AUPRC={auprc}, F1={f1}, Accuracy={accuracy}")
        
def setup_logging(log_file='model_training.log'):
    """è®¾ç½®æ—¥å¿—"""
    import logging
    
    logs_dir = FILE_PATHS['logs_dir']
    os.makedirs(logs_dir, exist_ok=True)
    
    log_path = os.path.join(logs_dir, log_file)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_path, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    
    return logging.getLogger(__name__) 