"""
ç‰¹å¾é€‰æ‹©æ•ˆèƒ½å¯¹æ¯”åˆ†æè¿è¡Œè„šæœ¬
"""

import sys
import os

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from cesd_depression_model.core.main_pipeline import CESDPredictionPipeline
from cesd_depression_model.analysis.performance_comparator import PerformanceComparator

def run_feature_selection_comparison():
    """è¿è¡Œç‰¹å¾é€‰æ‹©æ•ˆèƒ½å¯¹æ¯”åˆ†æ"""
    
    print("="*80)
    print("ğŸ” ç‰¹å¾é€‰æ‹© vs æ— ç‰¹å¾é€‰æ‹© æ•ˆèƒ½å¯¹æ¯”åˆ†æ")
    print("="*80)
    
    print("\nğŸ“‹ åˆ†æè¯´æ˜:")
    print("æœ¬æ¬¡åˆ†æå°†å¯¹æ¯”ä»¥ä¸‹é…ç½®çš„æ•ˆèƒ½å·®å¼‚ï¼š")
    print("1. ğŸš« æ— ç‰¹å¾é€‰æ‹© - ä½¿ç”¨å…¨éƒ¨42ä¸ªç‰¹å¾")
    print("2. ğŸ¯ ä¿å®ˆç‰¹å¾é€‰æ‹© - é€‰æ‹©20ä¸ªæœ€é‡è¦ç‰¹å¾") 
    print("3. âš¡ ä¸­ç­‰ç‰¹å¾é€‰æ‹© - é€‰æ‹©15ä¸ªå…³é”®ç‰¹å¾")
    print("4. ğŸ”¥ æ¿€è¿›ç‰¹å¾é€‰æ‹© - ä»…é€‰æ‹©10ä¸ªæ ¸å¿ƒç‰¹å¾")
    print("5. ğŸ“Š ç»Ÿè®¡ç‰¹å¾é€‰æ‹© - åŸºäºç»Ÿè®¡æ–¹æ³•é€‰æ‹©18ä¸ªç‰¹å¾")
    
    print("\nğŸ“Š å¯¹æ¯”ç»´åº¦:")
    print("- ğŸ¯ é¢„æµ‹æ€§èƒ½ (AUROC, F1-Score)")
    print("- â±ï¸ è®¡ç®—æ—¶é—´ (é¢„å¤„ç†, è®­ç»ƒ, è¯„ä¼°)")
    print("- ğŸ”¢ ç‰¹å¾ç»´åº¦ (åŸå§‹ vs é€‰æ‹©)")
    print("- ğŸ’¡ æ•ˆç‡æ”¶ç›Š (æ€§èƒ½æå‡ vs æ—¶é—´èŠ‚çœ)")
    
    try:
        # åˆ›å»ºæµæ°´çº¿å’Œå¯¹æ¯”åˆ†æå™¨
        pipeline = CESDPredictionPipeline(random_state=42)
        comparator = PerformanceComparator(random_state=42)
        
        # å®šä¹‰ç‰¹å¾é€‰æ‹©é…ç½®
        configs = [
            {
                'name': 'NoSelection',
                'use_feature_selection': False,
                'description': 'åŸºçº¿ï¼šæ— ç‰¹å¾é€‰æ‹©ï¼ˆå…¨éƒ¨42ä¸ªç‰¹å¾ï¼‰'
            },
            {
                'name': 'Conservative_20',
                'use_feature_selection': True,
                'k_best': 20,
                'methods': ['variance', 'univariate', 'rfe', 'model_based'],
                'description': 'ä¿å®ˆç­–ç•¥ï¼š4ç§æ–¹æ³•é€‰æ‹©20ä¸ªç‰¹å¾'
            },
            {
                'name': 'Moderate_15', 
                'use_feature_selection': True,
                'k_best': 15,
                'methods': ['univariate', 'rfe', 'model_based'],
                'description': 'ä¸­ç­‰ç­–ç•¥ï¼š3ç§æ–¹æ³•é€‰æ‹©15ä¸ªç‰¹å¾'
            },
            {
                'name': 'Aggressive_10',
                'use_feature_selection': True,
                'k_best': 10,
                'methods': ['rfe', 'model_based'],
                'description': 'æ¿€è¿›ç­–ç•¥ï¼š2ç§æ–¹æ³•é€‰æ‹©10ä¸ªç‰¹å¾'
            }
        ]
        
        print(f"\nâ³ å¼€å§‹æ•ˆèƒ½å¯¹æ¯”åˆ†æ...")
        print(f"   é¢„è®¡ç”¨æ—¶: 10-15åˆ†é’Ÿ")
        print(f"   æ•°æ®é›†: CHARLS 2018")
        
        # è¿è¡Œå…¨é¢å¯¹æ¯”åˆ†æ
        results = comparator.comprehensive_comparison(
            pipeline=pipeline,
            train_path="charls2018 20250722.csv",
            test_path=None,  # ä½¿ç”¨æ•°æ®åˆ†å‰²
            feature_selection_configs=configs
        )
        
        print("\n" + "="*80)
        print("ğŸ‰ ç‰¹å¾é€‰æ‹©æ•ˆèƒ½å¯¹æ¯”åˆ†æå®Œæˆï¼")
        print("="*80)
        
        # æ˜¾ç¤ºä¸»è¦ç»“è®º
        print_key_findings(results)
        
        print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("   ğŸ“Š feature_selection_performance_comparison.csv - æ€§èƒ½å¯¹æ¯”è¡¨")
        print("   ğŸ“ˆ feature_selection_comprehensive_comparison.png - å¯è§†åŒ–å¯¹æ¯”")
        print("   ğŸ“‹ feature_selection_summary_report_*.md - è¯¦ç»†åˆ†ææŠ¥å‘Š")
        print("   ğŸ“„ feature_selection_detailed_comparison_*.json - å®Œæ•´æ•°æ®")
        
        return results
        
    except Exception as e:
        print(f"\nâŒ æ•ˆèƒ½å¯¹æ¯”åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def print_key_findings(results):
    """æ‰“å°å…³é”®å‘ç°"""
    print("\nğŸ” å…³é”®å‘ç°æ€»ç»“:")
    
    if not results:
        print("   âŒ æ— æœ‰æ•ˆç»“æœ")
        return
    
    # æå–å…³é”®æ•°æ®
    baseline_auroc = 0
    best_auroc = 0
    best_config = None
    
    summary_data = []
    
    for config_name, result in results.items():
        if 'error' not in result:
            auroc = result['performance']['average']['auroc']
            features = result['feature_info']['selected_features']
            time_total = result['timing']['total']
            
            summary_data.append({
                'config': config_name,
                'auroc': auroc,
                'features': features,
                'time': time_total
            })
            
            if config_name == 'NoSelection':
                baseline_auroc = auroc
            elif auroc > best_auroc:
                best_auroc = auroc
                best_config = config_name
    
    # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
    for data in sorted(summary_data, key=lambda x: x['auroc'], reverse=True):
        if data['config'] == 'NoSelection':
            status = "ğŸ“ åŸºçº¿"
        elif data['config'] == best_config:
            status = "ğŸ† æœ€ä½³"
        else:
            status = "   "
        
        improvement = ((data['auroc'] - baseline_auroc) / baseline_auroc * 100) if baseline_auroc > 0 else 0
        
        print(f"   {status} {data['config']:15s}: AUROC {data['auroc']:.3f} "
              f"({improvement:+.1f}%), {data['features']:2d}ç‰¹å¾, {data['time']:4.1f}ç§’")
    
    # è®¡ç®—æ•ˆç‡æ”¶ç›Š
    if best_config and baseline_auroc > 0:
        best_data = next(d for d in summary_data if d['config'] == best_config)
        baseline_data = next(d for d in summary_data if d['config'] == 'NoSelection')
        
        performance_gain = ((best_data['auroc'] - baseline_data['auroc']) / baseline_data['auroc']) * 100
        feature_reduction = (1 - best_data['features'] / baseline_data['features']) * 100
        time_change = ((best_data['time'] - baseline_data['time']) / baseline_data['time']) * 100
        
        print(f"\nğŸ’¡ æ•ˆç‡æ”¶ç›Šåˆ†æ:")
        print(f"   ğŸ¯ æ€§èƒ½æå‡: {performance_gain:+.2f}%")
        print(f"   ğŸ“‰ ç‰¹å¾å‡å°‘: {feature_reduction:.1f}%")
        print(f"   â±ï¸ æ—¶é—´å˜åŒ–: {time_change:+.1f}%")
        
        # ç»™å‡ºå»ºè®®
        if performance_gain > 1.0:
            print(f"\nâœ… å»ºè®®: ä½¿ç”¨ {best_config} ç­–ç•¥")
            print(f"   ç†ç”±: æ˜¾è‘—æå‡æ€§èƒ½ ({performance_gain:+.1f}%)ï¼ŒåŒæ—¶å‡å°‘ç‰¹å¾ç»´åº¦")
        elif feature_reduction > 20 and performance_gain > -2.0:
            print(f"\nğŸ’¡ å»ºè®®: è€ƒè™‘ä½¿ç”¨ç‰¹å¾é€‰æ‹©")
            print(f"   ç†ç”±: å¤§å¹…å‡å°‘ç‰¹å¾ç»´åº¦ï¼Œæ€§èƒ½æŸå¤±å¯æ¥å—")
        else:
            print(f"\nğŸ¤” å»ºè®®: ä¿æŒå…¨ç‰¹å¾æˆ–è°ƒæ•´ç‰¹å¾é€‰æ‹©å‚æ•°")
            print(f"   ç†ç”±: å½“å‰ç‰¹å¾é€‰æ‹©ç­–ç•¥æ”¶ç›Šä¸æ˜æ˜¾")

def quick_comparison():
    """å¿«é€Ÿå¯¹æ¯”ç¤ºä¾‹"""
    print("\nğŸš€ å¿«é€Ÿå¯¹æ¯”ç¤ºä¾‹")
    print("-"*50)
    
    try:
        # åˆ›å»ºæµæ°´çº¿
        pipeline = CESDPredictionPipeline(random_state=42)
        
        # åŠ è½½æ•°æ®
        pipeline.load_and_preprocess_data("charls2018 20250722.csv", use_smote=False)
        
        print(f"åŸå§‹ç‰¹å¾æ•°: {pipeline.X_train.shape[1]}")
        
        # 1. è®­ç»ƒæ— ç‰¹å¾é€‰æ‹©æ¨¡å‹
        print("\nğŸ”§ è®­ç»ƒåŸºçº¿æ¨¡å‹ï¼ˆæ— ç‰¹å¾é€‰æ‹©ï¼‰...")
        import time
        start = time.time()
        pipeline.train_models(use_feature_selection=False)
        results_baseline = pipeline.evaluate_models(use_feature_selection=False)
        time_baseline = time.time() - start
        
        # 2. åº”ç”¨ç‰¹å¾é€‰æ‹©å¹¶è®­ç»ƒ
        print("\nğŸ” åº”ç”¨ç‰¹å¾é€‰æ‹©...")
        pipeline.apply_feature_selection(k_best=15)
        
        print("\nğŸ”§ è®­ç»ƒç‰¹å¾é€‰æ‹©æ¨¡å‹...")
        start = time.time()
        pipeline.train_models(use_feature_selection=True)
        results_selected = pipeline.evaluate_models(use_feature_selection=True)
        time_selected = time.time() - start
        
        # 3. å¯¹æ¯”ç»“æœ
        print(f"\nğŸ“Š å¿«é€Ÿå¯¹æ¯”ç»“æœ:")
        
        # è®¡ç®—å¹³å‡AUROC
        baseline_aurocs = [r['auroc']['value'] for r in results_baseline.values()]
        selected_aurocs = [r['auroc']['value'] for r in results_selected.values()]
        
        avg_baseline = sum(baseline_aurocs) / len(baseline_aurocs)
        avg_selected = sum(selected_aurocs) / len(selected_aurocs)
        
        improvement = ((avg_selected - avg_baseline) / avg_baseline) * 100
        
        print(f"   åŸºçº¿æ¨¡å‹ (42ç‰¹å¾): AUROC {avg_baseline:.3f}, ç”¨æ—¶ {time_baseline:.1f}ç§’")
        print(f"   ç‰¹å¾é€‰æ‹© (15ç‰¹å¾): AUROC {avg_selected:.3f}, ç”¨æ—¶ {time_selected:.1f}ç§’")
        print(f"   æ€§èƒ½å˜åŒ–: {improvement:+.2f}%")
        print(f"   ç‰¹å¾å‡å°‘: {(1-15/42)*100:.1f}%")
        
        return {
            'baseline': {'auroc': avg_baseline, 'time': time_baseline, 'features': 42},
            'selected': {'auroc': avg_selected, 'time': time_selected, 'features': 15},
            'improvement': improvement
        }
        
    except Exception as e:
        print(f"âŒ å¿«é€Ÿå¯¹æ¯”å¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    # é€‰æ‹©è¿è¡Œæ¨¡å¼
    print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. ğŸ” å®Œæ•´æ•ˆèƒ½å¯¹æ¯”åˆ†æ (æ¨èï¼Œçº¦15åˆ†é’Ÿ)")
    print("2. âš¡ å¿«é€Ÿå¯¹æ¯”ç¤ºä¾‹ (çº¦3åˆ†é’Ÿ)")
    
    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2ï¼Œé»˜è®¤1): ").strip() or "1"
    
    if choice == "2":
        quick_comparison()
    else:
        run_feature_selection_comparison()
    
    print("\nğŸ‰ åˆ†æå®Œæˆï¼") 