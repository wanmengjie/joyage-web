"""
ç‰¹å¾é€‰æ‹© + å‚æ•°ä¼˜åŒ–å®Œæ•´æ•ˆèƒ½å¯¹æ¯”åˆ†æ
"""

import sys
import os
import time

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from cesd_depression_model.core.main_pipeline import CESDPredictionPipeline
import pandas as pd
import numpy as np

def comprehensive_optimization_comparison():
    """
    å®Œæ•´çš„ä¼˜åŒ–ç­–ç•¥å¯¹æ¯”åˆ†æ
    å¯¹æ¯”4ç§ç­–ç•¥ï¼š
    1. åŸºçº¿ï¼šæ— ç‰¹å¾é€‰æ‹© + é»˜è®¤å‚æ•°
    2. ç‰¹å¾é€‰æ‹©ï¼šç‰¹å¾é€‰æ‹© + é»˜è®¤å‚æ•°
    3. å‚æ•°ä¼˜åŒ–ï¼šæ— ç‰¹å¾é€‰æ‹© + å‚æ•°è°ƒä¼˜
    4. åŒé‡ä¼˜åŒ–ï¼šç‰¹å¾é€‰æ‹© + å‚æ•°è°ƒä¼˜
    """
    
    print("="*80)
    print("ğŸ” ç‰¹å¾é€‰æ‹© + å‚æ•°ä¼˜åŒ– å®Œæ•´æ•ˆèƒ½å¯¹æ¯”åˆ†æ")
    print("="*80)
    
    print("\nğŸ“‹ å¯¹æ¯”ç­–ç•¥:")
    print("1. ğŸ“ åŸºçº¿ç­–ç•¥     - å…¨ç‰¹å¾(42) + é»˜è®¤å‚æ•°")
    print("2. ğŸ”§ ç‰¹å¾é€‰æ‹©     - ç²¾é€‰ç‰¹å¾(20) + é»˜è®¤å‚æ•°") 
    print("3. âš™ï¸ å‚æ•°ä¼˜åŒ–     - å…¨ç‰¹å¾(42) + è°ƒä¼˜å‚æ•°")
    print("4. ğŸš€ åŒé‡ä¼˜åŒ–     - ç²¾é€‰ç‰¹å¾(20) + è°ƒä¼˜å‚æ•°")
    
    print("\nğŸ“Š è¯„ä¼°ç»´åº¦:")
    print("- ğŸ¯ é¢„æµ‹æ€§èƒ½ (AUROC, F1-Score)")
    print("- â±ï¸ è®¡ç®—æ—¶é—´ (ç‰¹å¾é€‰æ‹© + å‚æ•°è°ƒä¼˜ + è®­ç»ƒ)")
    print("- ğŸ”¢ æ¨¡å‹å¤æ‚åº¦ (ç‰¹å¾æ•° + å‚æ•°æ•°)")
    print("- ğŸ’¡ ç»¼åˆæ•ˆç›Š (æ€§èƒ½/æ—¶é—´æ¯”)")
    
    strategies = [
        {
            'name': 'Baseline',
            'description': 'åŸºçº¿ï¼šå…¨ç‰¹å¾+é»˜è®¤å‚æ•°',
            'use_feature_selection': False,
            'use_hyperparameter_tuning': False,
            'k_best': 42
        },
        {
            'name': 'FeatureSelection',
            'description': 'ç‰¹å¾é€‰æ‹©ï¼šç²¾é€‰ç‰¹å¾+é»˜è®¤å‚æ•°',
            'use_feature_selection': True,
            'use_hyperparameter_tuning': False,
            'k_best': 20
        },
        {
            'name': 'HyperparameterTuning',
            'description': 'å‚æ•°ä¼˜åŒ–ï¼šå…¨ç‰¹å¾+è°ƒä¼˜å‚æ•°',
            'use_feature_selection': False,
            'use_hyperparameter_tuning': True,
            'k_best': 42
        },
        {
            'name': 'DoubleOptimization',
            'description': 'åŒé‡ä¼˜åŒ–ï¼šç²¾é€‰ç‰¹å¾+è°ƒä¼˜å‚æ•°',
            'use_feature_selection': True,
            'use_hyperparameter_tuning': True,
            'k_best': 20
        }
    ]
    
    results = {}
    
    for strategy in strategies:
        print(f"\n{'='*60}")
        print(f"ğŸ”§ æµ‹è¯•ç­–ç•¥: {strategy['name']}")
        print(f"ğŸ“ æè¿°: {strategy['description']}")
        print(f"{'='*60}")
        
        try:
            result = run_single_strategy(strategy)
            results[strategy['name']] = result
            
            print(f"âœ… {strategy['name']} å®Œæˆ")
            print(f"   ç‰¹å¾æ•°: {result['features']}")
            print(f"   æœ€ä½³AUROC: {result['best_auroc']:.3f}")
            print(f"   æ€»ç”¨æ—¶: {result['total_time']:.1f}ç§’")
            
        except Exception as e:
            print(f"âŒ {strategy['name']} å¤±è´¥: {e}")
            results[strategy['name']] = {'error': str(e)}
    
    # ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
    generate_comprehensive_analysis(results)
    
    return results

def run_single_strategy(strategy):
    """è¿è¡Œå•ä¸ªä¼˜åŒ–ç­–ç•¥"""
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    
    # åˆå§‹åŒ–æµæ°´çº¿
    pipeline = CESDPredictionPipeline(random_state=42)
    
    # 1. æ•°æ®é¢„å¤„ç†
    preprocessing_start = time.time()
    pipeline.load_and_preprocess_data("charls2018 20250722.csv", use_smote=False)
    preprocessing_time = time.time() - preprocessing_start
    
    result = {
        'strategy': strategy,
        'timing': {'preprocessing': preprocessing_time},
        'features': pipeline.X_train.shape[1],
        'samples': pipeline.X_train.shape[0]
    }
    
    # 2. ç‰¹å¾é€‰æ‹©ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if strategy['use_feature_selection']:
        fs_start = time.time()
        pipeline.apply_feature_selection(k_best=strategy['k_best'])
        fs_time = time.time() - fs_start
        
        result['timing']['feature_selection'] = fs_time
        result['features'] = strategy['k_best']
    else:
        result['timing']['feature_selection'] = 0
    
    # 3. æ¨¡å‹è®­ç»ƒ
    training_start = time.time()
    if strategy['use_feature_selection']:
        models = pipeline.train_models(use_feature_selection=True)
    else:
        models = pipeline.train_models(use_feature_selection=False)
    training_time = time.time() - training_start
    
    result['timing']['training'] = training_time
    result['models_count'] = len(models)
    
    # 4. å‚æ•°è°ƒä¼˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if strategy['use_hyperparameter_tuning']:
        tuning_start = time.time()
        tuned_models, benchmark_df = pipeline.run_hyperparameter_tuning(
            search_method='random', n_iter=10  # å‡å°‘è¿­ä»£æ¬¡æ•°ä»¥èŠ‚çœæ—¶é—´
        )
        tuning_time = time.time() - tuning_start
        
        result['timing']['hyperparameter_tuning'] = tuning_time
        
        # ä½¿ç”¨è°ƒä¼˜åçš„æ¨¡å‹
        if not benchmark_df.empty:
            best_model_name = benchmark_df.iloc[0]['Model']
            result['best_model'] = best_model_name
            result['best_auroc'] = benchmark_df.iloc[0]['Best_CV_AUC']
            result['tuning_improvement'] = result['best_auroc']
        else:
            result['best_auroc'] = 0
    else:
        result['timing']['hyperparameter_tuning'] = 0
        
        # 5. æ¨¡å‹è¯„ä¼°ï¼ˆå¦‚æœæ²¡æœ‰å‚æ•°è°ƒä¼˜ï¼‰
        eval_start = time.time()
        if strategy['use_feature_selection']:
            evaluation_results = pipeline.evaluate_models(use_feature_selection=True)
        else:
            evaluation_results = pipeline.evaluate_models(use_feature_selection=False)
        eval_time = time.time() - eval_start
        
        result['timing']['evaluation'] = eval_time
        
        # è®¡ç®—å¹³å‡AUROC
        if evaluation_results:
            aurocs = [res['auroc']['value'] for res in evaluation_results.values()]
            result['best_auroc'] = max(aurocs)
            result['avg_auroc'] = np.mean(aurocs)
        else:
            result['best_auroc'] = 0
            result['avg_auroc'] = 0
    
    # è®¡ç®—æ€»æ—¶é—´
    result['timing']['total'] = time.time() - start_time
    result['total_time'] = result['timing']['total']
    
    return result

def generate_comprehensive_analysis(results):
    """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
    
    print(f"\n{'='*80}")
    print("ğŸ“Š å®Œæ•´ä¼˜åŒ–ç­–ç•¥æ•ˆèƒ½å¯¹æ¯”æŠ¥å‘Š")
    print(f"{'='*80}")
    
    # 1. æ€§èƒ½å¯¹æ¯”è¡¨
    print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”")
    print("-" * 80)
    
    comparison_data = []
    
    for strategy_name, result in results.items():
        if 'error' not in result:
            comparison_data.append({
                'Strategy': strategy_name,
                'Features': result['features'],
                'Best_AUROC': result['best_auroc'],
                'Total_Time': result['total_time'],
                'FS_Time': result['timing'].get('feature_selection', 0),
                'HP_Time': result['timing'].get('hyperparameter_tuning', 0),
                'Training_Time': result['timing']['training']
            })
    
    if comparison_data:
        df = pd.DataFrame(comparison_data)
        df = df.sort_values('Best_AUROC', ascending=False)
        
        print(df.to_string(index=False, float_format='%.3f'))
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        df.to_csv('complete_optimization_comparison.csv', index=False, encoding='utf-8-sig')
        
        # 2. æ•ˆç‡åˆ†æ
        print(f"\nâš¡ æ•ˆç‡åˆ†æ")
        print("-" * 50)
        
        baseline_result = results.get('Baseline')
        if baseline_result and 'error' not in baseline_result:
            baseline_auroc = baseline_result['best_auroc']
            baseline_time = baseline_result['total_time']
            
            for _, row in df.iterrows():
                if row['Strategy'] != 'Baseline':
                    perf_improvement = ((row['Best_AUROC'] - baseline_auroc) / baseline_auroc * 100)
                    time_change = ((row['Total_Time'] - baseline_time) / baseline_time * 100)
                    efficiency = perf_improvement / (time_change + 1) if time_change > -100 else perf_improvement
                    
                    print(f"{row['Strategy']:20s}: AUROC {perf_improvement:+5.1f}%, "
                          f"æ—¶é—´ {time_change:+5.1f}%, æ•ˆç‡æ¯” {efficiency:5.1f}")
        
        # 3. æœ€ä½³ç­–ç•¥æ¨è
        print(f"\nğŸ’¡ ç­–ç•¥æ¨è")
        print("-" * 30)
        
        best_performance = df.iloc[0]
        fastest_strategy = df.loc[df['Total_Time'].idxmin()]
        
        print(f"ğŸ† æœ€ä½³æ€§èƒ½: {best_performance['Strategy']} "
              f"(AUROC: {best_performance['Best_AUROC']:.3f})")
        print(f"âš¡ æœ€å¿«ç­–ç•¥: {fastest_strategy['Strategy']} "
              f"(ç”¨æ—¶: {fastest_strategy['Total_Time']:.1f}ç§’)")
        
        # è®¡ç®—æ•ˆç‡æœ€ä¼˜ç­–ç•¥
        df['efficiency'] = df['Best_AUROC'] / (df['Total_Time'] / 60)  # AUROC per minute
        most_efficient = df.loc[df['efficiency'].idxmax()]
        
        print(f"â­ æ•ˆç‡æœ€ä¼˜: {most_efficient['Strategy']} "
              f"(æ•ˆç‡: {most_efficient['efficiency']:.4f} AUROC/åˆ†é’Ÿ)")
        
        # 4. åº”ç”¨å»ºè®®
        print(f"\nğŸ¯ åº”ç”¨å»ºè®®")
        print("-" * 20)
        
        if best_performance['Strategy'] == 'DoubleOptimization':
            print("âœ… æ¨èä½¿ç”¨åŒé‡ä¼˜åŒ–ç­–ç•¥ (ç‰¹å¾é€‰æ‹©+å‚æ•°è°ƒä¼˜)")
            print("   ç†ç”±: æ€§èƒ½æœ€ä¼˜ï¼Œå…¼é¡¾æ•ˆç‡å’Œæ•ˆæœ")
        elif best_performance['Strategy'] == 'FeatureSelection':
            print("âœ… æ¨èä½¿ç”¨ç‰¹å¾é€‰æ‹©ç­–ç•¥")
            print("   ç†ç”±: æ˜¾è‘—æå‡æ€§èƒ½ï¼Œè®¡ç®—æˆæœ¬é€‚ä¸­")
        elif best_performance['Strategy'] == 'HyperparameterTuning':
            print("âœ… æ¨èä½¿ç”¨å‚æ•°ä¼˜åŒ–ç­–ç•¥")
            print("   ç†ç”±: é€šè¿‡è°ƒå‚è·å¾—æœ€ä½³æ€§èƒ½")
        else:
            print("ğŸ¤” å½“å‰ä¼˜åŒ–ç­–ç•¥æ•ˆæœä¸æ˜æ˜¾ï¼Œå»ºè®®:")
            print("   - æ£€æŸ¥æ•°æ®è´¨é‡")
            print("   - è°ƒæ•´ç‰¹å¾é€‰æ‹©å‚æ•°")
            print("   - æ‰©å±•å‚æ•°æœç´¢ç©ºé—´")
    
    print(f"\nğŸ“ ç»“æœæ–‡ä»¶:")
    print("   ğŸ“Š complete_optimization_comparison.csv - è¯¦ç»†å¯¹æ¯”ç»“æœ")

def quick_optimization_demo():
    """å¿«é€Ÿä¼˜åŒ–æ¼”ç¤º"""
    
    print("\nğŸš€ å¿«é€Ÿä¼˜åŒ–æ¼”ç¤º")
    print("-"*50)
    
    try:
        pipeline = CESDPredictionPipeline(random_state=42)
        
        # åŠ è½½æ•°æ®
        pipeline.load_and_preprocess_data("charls2018 20250722.csv", use_smote=False)
        print(f"æ•°æ®åŠ è½½å®Œæˆ: {pipeline.X_train.shape}")
        
        # ç­–ç•¥1: ä»…ç‰¹å¾é€‰æ‹©
        print("\n1ï¸âƒ£ æµ‹è¯•ç‰¹å¾é€‰æ‹©æ•ˆæœ...")
        start = time.time()
        pipeline.apply_feature_selection(k_best=15)
        pipeline.train_models(use_feature_selection=True)
        fs_results = pipeline.evaluate_models(use_feature_selection=True)
        fs_time = time.time() - start
        
        fs_aurocs = [r['auroc']['value'] for r in fs_results.values()]
        fs_best = max(fs_aurocs)
        
        # ç­–ç•¥2: ä»…å‚æ•°è°ƒä¼˜
        print("\n2ï¸âƒ£ æµ‹è¯•å‚æ•°è°ƒä¼˜æ•ˆæœ...")
        pipeline2 = CESDPredictionPipeline(random_state=42)
        pipeline2.load_and_preprocess_data("charls2018 20250722.csv", use_smote=False)
        
        start = time.time()
        tuned_models, benchmark_df = pipeline2.run_hyperparameter_tuning(
            search_method='random', n_iter=5
        )
        hp_time = time.time() - start
        
        hp_best = benchmark_df.iloc[0]['Best_CV_AUC'] if not benchmark_df.empty else 0
        
        # å¯¹æ¯”ç»“æœ
        print(f"\nğŸ“Š å¿«é€Ÿå¯¹æ¯”ç»“æœ:")
        print(f"ç‰¹å¾é€‰æ‹©ç­–ç•¥: AUROC {fs_best:.3f}, ç”¨æ—¶ {fs_time:.1f}ç§’, ç‰¹å¾ {pipeline.X_train_selected.shape[1]}ä¸ª")
        print(f"å‚æ•°è°ƒä¼˜ç­–ç•¥: AUROC {hp_best:.3f}, ç”¨æ—¶ {hp_time:.1f}ç§’, ç‰¹å¾ {pipeline2.X_train.shape[1]}ä¸ª")
        
        improvement_fs = ((fs_best - 0.5) / 0.5) * 100  # å‡è®¾åŸºçº¿0.5
        improvement_hp = ((hp_best - 0.5) / 0.5) * 100
        
        if fs_best > hp_best:
            print(f"ğŸ’¡ å»ºè®®: ç‰¹å¾é€‰æ‹©æ•ˆæœæ›´å¥½ (+{improvement_fs:.1f}%)")
        else:
            print(f"ğŸ’¡ å»ºè®®: å‚æ•°è°ƒä¼˜æ•ˆæœæ›´å¥½ (+{improvement_hp:.1f}%)")
            
        return {
            'feature_selection': {'auroc': fs_best, 'time': fs_time, 'features': 15},
            'hyperparameter_tuning': {'auroc': hp_best, 'time': hp_time, 'features': 42}
        }
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    print("è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. ğŸ” å®Œæ•´ä¼˜åŒ–å¯¹æ¯”åˆ†æ (æ¨èï¼Œçº¦20-30åˆ†é’Ÿ)")
    print("2. âš¡ å¿«é€Ÿä¼˜åŒ–æ¼”ç¤º (çº¦5åˆ†é’Ÿ)")
    
    choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1/2ï¼Œé»˜è®¤2): ").strip() or "2"
    
    if choice == "1":
        comprehensive_optimization_comparison()
    else:
        quick_optimization_demo()
    
    print("\nğŸ‰ ä¼˜åŒ–å¯¹æ¯”åˆ†æå®Œæˆï¼") 