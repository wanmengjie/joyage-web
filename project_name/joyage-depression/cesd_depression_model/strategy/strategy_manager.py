"""
ç³»ç»ŸåŒ–ç­–ç•¥ç®¡ç†æ¡†æ¶
Strategy Management Framework for CESD Depression Prediction
"""

import json
import pandas as pd
import numpy as np
import time
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Tuple, Union
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

class StrategyType(Enum):
    """ç­–ç•¥ç±»å‹æšä¸¾"""
    BASELINE = "baseline"
    FEATURE_SELECTION = "feature_selection"  
    HYPERPARAMETER_TUNING = "hyperparameter_tuning"
    ENSEMBLE_OPTIMIZATION = "ensemble_optimization"
    CROSS_VALIDATION = "cross_validation"
    EXTERNAL_VALIDATION = "external_validation"
    FULL_PIPELINE = "full_pipeline"

class Priority(Enum):
    """ä¼˜å…ˆçº§æšä¸¾"""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class StrategyConfig:
    """ç­–ç•¥é…ç½®æ•°æ®ç±»"""
    name: str
    description: str
    strategy_type: StrategyType
    priority: Priority
    estimated_time: int  # åˆ†é’Ÿ
    dependencies: List[str]  # ä¾èµ–çš„ç­–ç•¥
    parameters: Dict
    expected_improvement: float  # é¢„æœŸæ€§èƒ½æå‡ç™¾åˆ†æ¯”
    resource_requirement: str  # èµ„æºéœ€æ±‚ï¼ˆä½/ä¸­/é«˜ï¼‰
    
class StrategyResult:
    """ç­–ç•¥æ‰§è¡Œç»“æœ"""
    def __init__(self, strategy_name: str):
        self.strategy_name = strategy_name
        self.start_time = None
        self.end_time = None
        self.duration = 0
        self.success = False
        self.metrics = {}
        self.artifacts = []  # ç”Ÿæˆçš„æ–‡ä»¶
        self.error_message = None
        self.performance_gain = 0
        
    def to_dict(self):
        return {
            'strategy_name': self.strategy_name,
            'start_time': self.start_time.isoformat() if self.start_time else None,
            'end_time': self.end_time.isoformat() if self.end_time else None,
            'duration': self.duration,
            'success': self.success,
            'metrics': self.metrics,
            'artifacts': self.artifacts,
            'error_message': self.error_message,
            'performance_gain': self.performance_gain
        }

class StrategyManager:
    """ç­–ç•¥ç®¡ç†å™¨ - ç³»ç»ŸåŒ–ç®¡ç†æ‰€æœ‰ä¼˜åŒ–ç­–ç•¥"""
    
    def __init__(self, workspace_dir: str = "."):
        self.workspace_dir = Path(workspace_dir)
        self.strategies = {}
        self.execution_history = []
        self.current_baseline = None
        self.best_strategy = None
        self.results_dir = self.workspace_dir / "strategy_results"
        self.results_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–é¢„å®šä¹‰ç­–ç•¥
        self._initialize_strategies()
        
    def _initialize_strategies(self):
        """åˆå§‹åŒ–é¢„å®šä¹‰çš„ä¼˜åŒ–ç­–ç•¥"""
        
        # 1. åŸºçº¿ç­–ç•¥
        self.add_strategy(StrategyConfig(
            name="baseline",
            description="åŸºçº¿ç­–ç•¥ï¼šå…¨ç‰¹å¾+é»˜è®¤å‚æ•°+æ ‡å‡†éªŒè¯",
            strategy_type=StrategyType.BASELINE,
            priority=Priority.HIGH,
            estimated_time=5,
            dependencies=[],
            parameters={
                'use_feature_selection': False,
                'use_hyperparameter_tuning': False,
                'use_cross_validation': True,
                'cv_folds': 5
            },
            expected_improvement=0.0,
            resource_requirement="ä½"
        ))
        
        # 2. ç‰¹å¾é€‰æ‹©ç­–ç•¥
        self.add_strategy(StrategyConfig(
            name="feature_selection_conservative",
            description="ä¿å®ˆç‰¹å¾é€‰æ‹©ï¼šå¤šæ–¹æ³•é›†æˆé€‰æ‹©å…³é”®ç‰¹å¾",
            strategy_type=StrategyType.FEATURE_SELECTION,
            priority=Priority.HIGH,
            estimated_time=8,
            dependencies=["baseline"],
            parameters={
                'methods': ['variance', 'univariate', 'rfe'],
                'k_best': 20,
                'variance_threshold': 0.01,
                'use_ensemble_voting': True
            },
            expected_improvement=2.5,
            resource_requirement="ä¸­"
        ))
        
        # 3. æ¿€è¿›ç‰¹å¾é€‰æ‹©ç­–ç•¥
        self.add_strategy(StrategyConfig(
            name="feature_selection_aggressive",
            description="æ¿€è¿›ç‰¹å¾é€‰æ‹©ï¼šæ·±åº¦ç‰¹å¾ç­›é€‰",
            strategy_type=StrategyType.FEATURE_SELECTION,
            priority=Priority.MEDIUM,
            estimated_time=12,
            dependencies=["baseline"],
            parameters={
                'methods': ['variance', 'univariate', 'rfe', 'model_based'],
                'k_best': 15,
                'variance_threshold': 0.05,
                'use_ensemble_voting': True,
                'recursive_elimination': True
            },
            expected_improvement=3.8,
            resource_requirement="ä¸­"
        ))
        
        # 4. è½»é‡çº§å‚æ•°è°ƒä¼˜
        self.add_strategy(StrategyConfig(
            name="hyperparameter_tuning_light",
            description="è½»é‡çº§å‚æ•°è°ƒä¼˜ï¼šå¿«é€Ÿå‚æ•°æœç´¢",
            strategy_type=StrategyType.HYPERPARAMETER_TUNING,
            priority=Priority.HIGH,
            estimated_time=15,
            dependencies=["baseline"],
            parameters={
                'search_method': 'random',
                'n_iter': 10,
                'cv_folds': 3,
                'models': ['rf', 'gb', 'xgb']
            },
            expected_improvement=3.2,
            resource_requirement="ä¸­"
        ))
        
        # 5. æ·±åº¦å‚æ•°è°ƒä¼˜
        self.add_strategy(StrategyConfig(
            name="hyperparameter_tuning_deep",
            description="æ·±åº¦å‚æ•°è°ƒä¼˜ï¼šå…¨é¢å‚æ•°æœç´¢",
            strategy_type=StrategyType.HYPERPARAMETER_TUNING,
            priority=Priority.MEDIUM,
            estimated_time=45,
            dependencies=["baseline"],
            parameters={
                'search_method': 'random',
                'n_iter': 50,
                'cv_folds': 5,
                'models': ['rf', 'gb', 'xgb', 'lgb', 'lr', 'svm']
            },
            expected_improvement=5.1,
            resource_requirement="é«˜"
        ))
        
        # 6. åŒé‡ä¼˜åŒ–ç­–ç•¥
        self.add_strategy(StrategyConfig(
            name="double_optimization",
            description="åŒé‡ä¼˜åŒ–ï¼šç‰¹å¾é€‰æ‹©+å‚æ•°è°ƒä¼˜",
            strategy_type=StrategyType.ENSEMBLE_OPTIMIZATION,
            priority=Priority.HIGH,
            estimated_time=25,
            dependencies=["feature_selection_conservative", "hyperparameter_tuning_light"],
            parameters={
                'feature_selection': {
                    'methods': ['variance', 'univariate', 'rfe'],
                    'k_best': 20
                },
                'hyperparameter_tuning': {
                    'search_method': 'random',
                    'n_iter': 15
                }
            },
            expected_improvement=4.8,
            resource_requirement="ä¸­"
        ))
        
        # 7. ç»ˆæä¼˜åŒ–ç­–ç•¥
        self.add_strategy(StrategyConfig(
            name="ultimate_optimization",
            description="ç»ˆæä¼˜åŒ–ï¼šæœ€å…¨é¢çš„ä¼˜åŒ–ç»„åˆ",
            strategy_type=StrategyType.ENSEMBLE_OPTIMIZATION,
            priority=Priority.MEDIUM,
            estimated_time=60,
            dependencies=["feature_selection_aggressive", "hyperparameter_tuning_deep"],
            parameters={
                'feature_selection': {
                    'methods': ['variance', 'univariate', 'rfe', 'model_based'],
                    'k_best': 15
                },
                'hyperparameter_tuning': {
                    'search_method': 'random',
                    'n_iter': 30
                },
                'ensemble_methods': True,
                'stacking_optimization': True
            },
            expected_improvement=7.5,
            resource_requirement="é«˜"
        ))
        
        # 8. å¤–éƒ¨éªŒè¯ç­–ç•¥
        self.add_strategy(StrategyConfig(
            name="external_validation",
            description="å¤–éƒ¨éªŒè¯ï¼šKLOSAæ•°æ®é›†éªŒè¯",
            strategy_type=StrategyType.EXTERNAL_VALIDATION,
            priority=Priority.HIGH,
            estimated_time=10,
            dependencies=["double_optimization"],
            parameters={
                'external_datasets': ['klosa2018 20250722.csv'],
                'generate_shap': True,
                'save_predictions': True
            },
            expected_improvement=0.0,  # éªŒè¯ä¸æ”¹å–„æ€§èƒ½ï¼Œä½†éªŒè¯æ³›åŒ–èƒ½åŠ›
            resource_requirement="ä½"
        ))
        
    def add_strategy(self, strategy_config: StrategyConfig):
        """æ·»åŠ æ–°ç­–ç•¥"""
        self.strategies[strategy_config.name] = strategy_config
        print(f"âœ… ç­–ç•¥å·²æ·»åŠ : {strategy_config.name}")
        
    def get_strategy_dependency_graph(self) -> Dict:
        """è·å–ç­–ç•¥ä¾èµ–å›¾"""
        graph = {}
        for name, strategy in self.strategies.items():
            graph[name] = {
                'dependencies': strategy.dependencies,
                'priority': strategy.priority.value,
                'estimated_time': strategy.estimated_time,
                'expected_improvement': strategy.expected_improvement
            }
        return graph
        
    def recommend_strategy_sequence(self, 
                                   available_time: int = 60,  # å¯ç”¨æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
                                   performance_target: float = 5.0,  # æ€§èƒ½æå‡ç›®æ ‡ï¼ˆ%ï¼‰
                                   resource_constraint: str = "ä¸­"  # èµ„æºçº¦æŸ
                                   ) -> List[str]:
        """æ™ºèƒ½æ¨èç­–ç•¥æ‰§è¡Œåºåˆ—"""
        
        print(f"\nğŸ¯ ç­–ç•¥æ¨èåˆ†æ")
        print(f"å¯ç”¨æ—¶é—´: {available_time}åˆ†é’Ÿ")
        print(f"æ€§èƒ½ç›®æ ‡: +{performance_target}%")
        print(f"èµ„æºçº¦æŸ: {resource_constraint}")
        print("-" * 50)
        
        # èµ„æºçº¦æŸæ˜ å°„
        resource_map = {"ä½": 1, "ä¸­": 2, "é«˜": 3}
        max_resource = resource_map.get(resource_constraint, 2)
        
        # è¿‡æ»¤å¯æ‰§è¡Œçš„ç­–ç•¥
        eligible_strategies = []
        for name, strategy in self.strategies.items():
            strategy_resource = resource_map.get(strategy.resource_requirement, 2)
            if strategy_resource <= max_resource:
                eligible_strategies.append((name, strategy))
        
        # ä¾èµ–å…³ç³»æ’åº
        sequence = []
        completed = set()
        total_time = 0
        total_improvement = 0
        
        # é¦–å…ˆæ·»åŠ åŸºçº¿ç­–ç•¥
        if "baseline" in self.strategies and "baseline" not in completed:
            sequence.append("baseline")
            completed.add("baseline")
            total_time += self.strategies["baseline"].estimated_time
            print(f"ğŸ“ åŸºçº¿ç­–ç•¥: {self.strategies['baseline'].estimated_time}åˆ†é’Ÿ")
        
        # æŒ‰ä¼˜å…ˆçº§å’Œæ•ˆç›Šæ¯”æ’åºå…¶ä»–ç­–ç•¥
        remaining_strategies = [
            (name, strategy) for name, strategy in eligible_strategies 
            if name not in completed
        ]
        
        # è®¡ç®—æ•ˆç›Šæ—¶é—´æ¯”
        strategy_scores = []
        for name, strategy in remaining_strategies:
            if self._dependencies_satisfied(strategy.dependencies, completed):
                efficiency = strategy.expected_improvement / max(strategy.estimated_time, 1)
                priority_weight = strategy.priority.value
                score = efficiency * priority_weight
                strategy_scores.append((score, name, strategy))
        
        # æŒ‰åˆ†æ•°æ’åº
        strategy_scores.sort(reverse=True)
        
        # è´ªå¿ƒé€‰æ‹©ç­–ç•¥
        for score, name, strategy in strategy_scores:
            if total_time + strategy.estimated_time <= available_time:
                if self._dependencies_satisfied(strategy.dependencies, completed):
                    sequence.append(name)
                    completed.add(name)
                    total_time += strategy.estimated_time
                    total_improvement += strategy.expected_improvement
                    
                    print(f"âœ… {name}: +{strategy.expected_improvement}%, {strategy.estimated_time}åˆ†é’Ÿ")
                    
                    if total_improvement >= performance_target:
                        print(f"ğŸ¯ å·²è¾¾åˆ°æ€§èƒ½ç›®æ ‡!")
                        break
        
        print(f"\nğŸ“Š æ¨èç»“æœ:")
        print(f"ç­–ç•¥åºåˆ—: {' â†’ '.join(sequence)}")
        print(f"é¢„è®¡æ€»æ—¶é—´: {total_time}åˆ†é’Ÿ")
        print(f"é¢„æœŸæ€§èƒ½æå‡: +{total_improvement:.1f}%")
        
        return sequence
    
    def _dependencies_satisfied(self, dependencies: List[str], completed: set) -> bool:
        """æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³"""
        return all(dep in completed for dep in dependencies)
    
    def execute_strategy_sequence(self, 
                                 strategy_names: List[str],
                                 pipeline,
                                 train_path: str,
                                 test_path: Optional[str] = None) -> Dict[str, StrategyResult]:
        """æ‰§è¡Œç­–ç•¥åºåˆ—"""
        
        print(f"\n{'='*80}")
        print("ğŸš€ å¼€å§‹æ‰§è¡Œç­–ç•¥åºåˆ—")
        print(f"ç­–ç•¥æ•°é‡: {len(strategy_names)}")
        print(f"{'='*80}")
        
        results = {}
        baseline_performance = None
        
        for i, strategy_name in enumerate(strategy_names, 1):
            print(f"\n{'='*60}")
            print(f"ğŸ“‹ æ‰§è¡Œç­–ç•¥ {i}/{len(strategy_names)}: {strategy_name}")
            print(f"{'='*60}")
            
            if strategy_name not in self.strategies:
                print(f"âŒ ç­–ç•¥ä¸å­˜åœ¨: {strategy_name}")
                continue
                
            strategy_config = self.strategies[strategy_name]
            result = self._execute_single_strategy(strategy_config, pipeline, train_path, test_path)
            results[strategy_name] = result
            
            # æ›´æ–°åŸºçº¿æ€§èƒ½
            if strategy_name == "baseline":
                baseline_performance = result.metrics.get('best_auroc', 0)
                self.current_baseline = result
            
            # è®¡ç®—æ€§èƒ½æå‡
            if baseline_performance and result.success:
                current_performance = result.metrics.get('best_auroc', 0)
                result.performance_gain = ((current_performance - baseline_performance) / baseline_performance) * 100
                
                # æ›´æ–°æœ€ä½³ç­–ç•¥
                if not self.best_strategy or current_performance > self.best_strategy.metrics.get('best_auroc', 0):
                    self.best_strategy = result
        
        # ä¿å­˜æ‰§è¡Œå†å²
        self.execution_history.append({
            'timestamp': datetime.now().isoformat(),
            'strategies': strategy_names,
            'results': {name: result.to_dict() for name, result in results.items()}
        })
        
        # ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š
        self._generate_execution_report(results)
        
        return results
    
    def _execute_single_strategy(self, 
                                strategy_config: StrategyConfig, 
                                pipeline,
                                train_path: str,
                                test_path: Optional[str] = None) -> StrategyResult:
        """æ‰§è¡Œå•ä¸ªç­–ç•¥"""
        
        result = StrategyResult(strategy_config.name)
        result.start_time = datetime.now()
        
        try:
            print(f"ğŸ“ ç­–ç•¥æè¿°: {strategy_config.description}")
            print(f"â±ï¸ é¢„è®¡æ—¶é—´: {strategy_config.estimated_time}åˆ†é’Ÿ")
            print(f"ğŸ¯ é¢„æœŸæå‡: +{strategy_config.expected_improvement}%")
            
            if strategy_config.strategy_type == StrategyType.BASELINE:
                result = self._execute_baseline_strategy(pipeline, train_path, test_path, result)
                
            elif strategy_config.strategy_type == StrategyType.FEATURE_SELECTION:
                result = self._execute_feature_selection_strategy(pipeline, strategy_config.parameters, result)
                
            elif strategy_config.strategy_type == StrategyType.HYPERPARAMETER_TUNING:
                result = self._execute_hyperparameter_tuning_strategy(pipeline, strategy_config.parameters, result)
                
            elif strategy_config.strategy_type == StrategyType.ENSEMBLE_OPTIMIZATION:
                result = self._execute_ensemble_optimization_strategy(pipeline, strategy_config.parameters, result)
                
            elif strategy_config.strategy_type == StrategyType.EXTERNAL_VALIDATION:
                result = self._execute_external_validation_strategy(pipeline, strategy_config.parameters, test_path, result)
            
            result.success = True
            print(f"âœ… ç­–ç•¥æ‰§è¡ŒæˆåŠŸ")
            
        except Exception as e:
            result.error_message = str(e)
            result.success = False
            print(f"âŒ ç­–ç•¥æ‰§è¡Œå¤±è´¥: {e}")
            
        result.end_time = datetime.now()
        result.duration = (result.end_time - result.start_time).total_seconds() / 60  # è½¬æ¢ä¸ºåˆ†é’Ÿ
        
        return result
    
    def _execute_baseline_strategy(self, pipeline, train_path, test_path, result):
        """æ‰§è¡ŒåŸºçº¿ç­–ç•¥"""
        
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        pipeline.load_and_preprocess_data(train_path, test_path, use_smote=False)
        
        # è®­ç»ƒæ¨¡å‹
        models = pipeline.train_models(use_feature_selection=False)
        
        # è¯„ä¼°æ¨¡å‹
        evaluation_results = pipeline.evaluate_models()
        
        # è®°å½•ç»“æœ
        if evaluation_results:
            aurocs = [res['auroc']['value'] for res in evaluation_results.values()]
            result.metrics = {
                'best_auroc': max(aurocs),
                'avg_auroc': np.mean(aurocs),
                'model_count': len(models),
                'feature_count': pipeline.X_train.shape[1],
                'sample_count': pipeline.X_train.shape[0]
            }
            
        result.artifacts = ['model_comparison_results.csv']
        return result
    
    def _execute_feature_selection_strategy(self, pipeline, parameters, result):
        """æ‰§è¡Œç‰¹å¾é€‰æ‹©ç­–ç•¥"""
        
        # åº”ç”¨ç‰¹å¾é€‰æ‹©
        summary = pipeline.apply_feature_selection(
            methods=parameters.get('methods', ['variance', 'univariate', 'rfe']),
            k_best=parameters.get('k_best', 20),
            variance_threshold=parameters.get('variance_threshold', 0.01)
        )
        
        # è®­ç»ƒæ¨¡å‹
        models = pipeline.train_models(use_feature_selection=True)
        
        # è¯„ä¼°æ¨¡å‹
        evaluation_results = pipeline.evaluate_models(use_feature_selection=True)
        
        # è®°å½•ç»“æœ
        if evaluation_results:
            aurocs = [res['auroc']['value'] for res in evaluation_results.values()]
            result.metrics = {
                'best_auroc': max(aurocs),
                'avg_auroc': np.mean(aurocs),
                'selected_features': pipeline.X_train_selected.shape[1],
                'original_features': pipeline.X_train.shape[1],
                'feature_reduction': pipeline.X_train.shape[1] - pipeline.X_train_selected.shape[1]
            }
            
        result.artifacts = ['feature_selection_results.csv', 'model_comparison_results.csv']
        return result
    
    def _execute_hyperparameter_tuning_strategy(self, pipeline, parameters, result):
        """æ‰§è¡Œè¶…å‚æ•°è°ƒä¼˜ç­–ç•¥"""
        
        tuned_models, benchmark_df = pipeline.run_hyperparameter_tuning(
            search_method=parameters.get('search_method', 'random'),
            n_iter=parameters.get('n_iter', 20)
        )
        
        # è®°å½•ç»“æœ
        if not benchmark_df.empty:
            result.metrics = {
                'best_auroc': benchmark_df.iloc[0]['Best_CV_AUC'],
                'best_model': benchmark_df.iloc[0]['Model'],
                'tuned_models': len(tuned_models),
                'search_iterations': parameters.get('n_iter', 20)
            }
            
        result.artifacts = ['hyperparameter_tuning_results.csv']
        return result
    
    def _execute_ensemble_optimization_strategy(self, pipeline, parameters, result):
        """æ‰§è¡Œé›†æˆä¼˜åŒ–ç­–ç•¥"""
        
        # å…ˆç‰¹å¾é€‰æ‹©
        if 'feature_selection' in parameters:
            fs_params = parameters['feature_selection']
            pipeline.apply_feature_selection(
                methods=fs_params.get('methods', ['variance', 'univariate', 'rfe']),
                k_best=fs_params.get('k_best', 20)
            )
            use_fs = True
        else:
            use_fs = False
        
        # è®­ç»ƒæ¨¡å‹
        models = pipeline.train_models(use_feature_selection=use_fs)
        
        # å‚æ•°è°ƒä¼˜
        if 'hyperparameter_tuning' in parameters:
            hp_params = parameters['hyperparameter_tuning']
            tuned_models, benchmark_df = pipeline.run_hyperparameter_tuning(
                search_method=hp_params.get('search_method', 'random'),
                n_iter=hp_params.get('n_iter', 15)
            )
            
            if not benchmark_df.empty:
                result.metrics = {
                    'best_auroc': benchmark_df.iloc[0]['Best_CV_AUC'],
                    'best_model': benchmark_df.iloc[0]['Model'],
                    'features_used': pipeline.X_train_selected.shape[1] if use_fs else pipeline.X_train.shape[1],
                    'optimization_type': 'double' if use_fs else 'hyperparameter_only'
                }
        
        result.artifacts = ['hyperparameter_tuning_results.csv']
        if use_fs:
            result.artifacts.append('feature_selection_results.csv')
            
        return result
    
    def _execute_external_validation_strategy(self, pipeline, parameters, test_path, result):
        """æ‰§è¡Œå¤–éƒ¨éªŒè¯ç­–ç•¥"""
        
        if not test_path:
            raise ValueError("å¤–éƒ¨éªŒè¯éœ€è¦æä¾›æµ‹è¯•æ•°æ®è·¯å¾„")
            
        # æ‰§è¡Œå¤–éƒ¨éªŒè¯
        external_results = pipeline.run_external_validation(test_path)
        
        # SHAPåˆ†æ
        if parameters.get('generate_shap', False):
            pipeline.generate_shap_analysis(
                datasets=['train', 'test'], 
                external_data_paths=[test_path]
            )
            
        result.metrics = {
            'external_auroc': external_results.get('auroc', 0) if external_results else 0,
            'external_dataset': test_path,
            'shap_generated': parameters.get('generate_shap', False)
        }
        
        result.artifacts = ['klosa_external_validation_results.csv']
        if parameters.get('generate_shap', False):
            result.artifacts.extend(['shap_plots_klosa_external/'])
            
        return result
    
    def _generate_execution_report(self, results: Dict[str, StrategyResult]):
        """ç”Ÿæˆæ‰§è¡ŒæŠ¥å‘Š"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = self.results_dir / f"strategy_execution_report_{timestamp}.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ç­–ç•¥æ‰§è¡ŒæŠ¥å‘Š\n\n")
            f.write(f"æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ‰§è¡Œç­–ç•¥æ•°: {len(results)}\n\n")
            
            # æ‰§è¡Œæ‘˜è¦
            f.write("## ğŸ“Š æ‰§è¡Œæ‘˜è¦\n\n")
            f.write("| ç­–ç•¥åç§° | çŠ¶æ€ | æ‰§è¡Œæ—¶é—´(åˆ†) | æœ€ä½³AUROC | æ€§èƒ½æå‡ |\n")
            f.write("|----------|------|-------------|-----------|----------|\n")
            
            for name, result in results.items():
                status = "âœ… æˆåŠŸ" if result.success else "âŒ å¤±è´¥"
                auroc = result.metrics.get('best_auroc', 0)
                gain = result.performance_gain
                f.write(f"| {name} | {status} | {result.duration:.1f} | {auroc:.3f} | {gain:+.1f}% |\n")
            
            # è¯¦ç»†ç»“æœ
            f.write("\n## ğŸ“‹ è¯¦ç»†ç»“æœ\n\n")
            for name, result in results.items():
                f.write(f"### {name}\n")
                f.write(f"- æè¿°: {self.strategies[name].description}\n")
                f.write(f"- çŠ¶æ€: {'æˆåŠŸ' if result.success else 'å¤±è´¥'}\n")
                f.write(f"- æ‰§è¡Œæ—¶é—´: {result.duration:.1f}åˆ†é’Ÿ\n")
                
                if result.success:
                    f.write(f"- ä¸»è¦æŒ‡æ ‡:\n")
                    for metric, value in result.metrics.items():
                        f.write(f"  - {metric}: {value}\n")
                    f.write(f"- ç”Ÿæˆæ–‡ä»¶: {', '.join(result.artifacts)}\n")
                else:
                    f.write(f"- é”™è¯¯ä¿¡æ¯: {result.error_message}\n")
                f.write("\n")
            
            # æœ€ä½³ç­–ç•¥æ¨è
            if self.best_strategy:
                f.write("## ğŸ† æœ€ä½³ç­–ç•¥\n\n")
                f.write(f"æœ€ä½³ç­–ç•¥: **{self.best_strategy.strategy_name}**\n")
                f.write(f"æœ€ä½³æ€§èƒ½: {self.best_strategy.metrics.get('best_auroc', 0):.3f}\n")
                f.write(f"æ€§èƒ½æå‡: {self.best_strategy.performance_gain:+.1f}%\n\n")
        
        print(f"\nğŸ“„ æ‰§è¡ŒæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
    def get_strategy_recommendations(self, context: Dict) -> Dict:
        """åŸºäºä¸Šä¸‹æ–‡è·å–ç­–ç•¥æ¨è"""
        
        recommendations = {
            'quick_wins': [],      # å¿«é€Ÿè§æ•ˆçš„ç­–ç•¥
            'high_impact': [],     # é«˜å½±å“åŠ›ç­–ç•¥  
            'resource_efficient': [], # èµ„æºé«˜æ•ˆç­–ç•¥
            'comprehensive': []    # ç»¼åˆç­–ç•¥
        }
        
        for name, strategy in self.strategies.items():
            efficiency = strategy.expected_improvement / max(strategy.estimated_time, 1)
            
            # å¿«é€Ÿè§æ•ˆï¼ˆæ—¶é—´çŸ­ã€æœ‰ä¸€å®šæ•ˆæœï¼‰
            if strategy.estimated_time <= 10 and strategy.expected_improvement >= 2:
                recommendations['quick_wins'].append((name, strategy))
            
            # é«˜å½±å“åŠ›ï¼ˆæœŸæœ›æå‡å¤§ï¼‰
            if strategy.expected_improvement >= 4:
                recommendations['high_impact'].append((name, strategy))
            
            # èµ„æºé«˜æ•ˆï¼ˆæ•ˆç‡é«˜ï¼‰
            if efficiency >= 0.3:
                recommendations['resource_efficient'].append((name, strategy))
            
            # ç»¼åˆç­–ç•¥ï¼ˆé›†æˆä¼˜åŒ–ï¼‰
            if strategy.strategy_type == StrategyType.ENSEMBLE_OPTIMIZATION:
                recommendations['comprehensive'].append((name, strategy))
        
        return recommendations

# é¢„å®šä¹‰çš„ç­–ç•¥ç»„åˆæ–¹æ¡ˆ
STRATEGY_PRESETS = {
    'quick_start': {
        'name': 'å¿«é€Ÿå¯åŠ¨æ–¹æ¡ˆ',
        'description': 'é€‚åˆåˆæ¬¡å°è¯•ï¼Œå¿«é€Ÿè·å¾—åŸºæœ¬ç»“æœ',
        'strategies': ['baseline', 'feature_selection_conservative'],
        'estimated_time': 13,
        'target_users': 'åˆå­¦è€…ã€æ—¶é—´ç´§å¼ '
    },
    
    'balanced': {
        'name': 'å¹³è¡¡ä¼˜åŒ–æ–¹æ¡ˆ', 
        'description': 'åœ¨æ—¶é—´å’Œæ€§èƒ½é—´å–å¾—å¹³è¡¡',
        'strategies': ['baseline', 'feature_selection_conservative', 'hyperparameter_tuning_light', 'double_optimization'],
        'estimated_time': 48,
        'target_users': 'ä¸€èˆ¬ç ”ç©¶ã€è®ºæ–‡å‘è¡¨'
    },
    
    'performance_focused': {
        'name': 'æ€§èƒ½å¯¼å‘æ–¹æ¡ˆ',
        'description': 'è¿½æ±‚æœ€ä½³æ€§èƒ½ï¼Œé€‚åˆç«èµ›å’Œå…³é”®åº”ç”¨',
        'strategies': ['baseline', 'feature_selection_aggressive', 'hyperparameter_tuning_deep', 'ultimate_optimization', 'external_validation'],
        'estimated_time': 127,
        'target_users': 'æœºå™¨å­¦ä¹ ç«èµ›ã€å…³é”®ä¸šåŠ¡'
    },
    
    'research_grade': {
        'name': 'ç§‘ç ”çº§æ–¹æ¡ˆ',
        'description': 'å…¨é¢çš„å®éªŒè®¾è®¡ï¼Œé€‚åˆé«˜è´¨é‡ç ”ç©¶',
        'strategies': ['baseline', 'feature_selection_conservative', 'feature_selection_aggressive', 
                      'hyperparameter_tuning_light', 'hyperparameter_tuning_deep', 'double_optimization', 
                      'ultimate_optimization', 'external_validation'],
        'estimated_time': 185,
        'target_users': 'å­¦æœ¯ç ”ç©¶ã€é¡¶çº§æœŸåˆŠ'
    }
}

def create_strategy_manager_demo():
    """åˆ›å»ºç­–ç•¥ç®¡ç†å™¨æ¼”ç¤º"""
    
    print("ğŸ¯ ç­–ç•¥ç®¡ç†å™¨æ¼”ç¤º")
    print("="*60)
    
    # åˆå§‹åŒ–ç­–ç•¥ç®¡ç†å™¨
    manager = StrategyManager()
    
    print(f"\nğŸ“‹ å¯ç”¨ç­–ç•¥: {len(manager.strategies)} ä¸ª")
    for name, strategy in manager.strategies.items():
        print(f"  {name}: {strategy.description}")
    
    print(f"\nğŸ“¦ é¢„è®¾æ–¹æ¡ˆ: {len(STRATEGY_PRESETS)} ä¸ª")
    for preset_name, preset in STRATEGY_PRESETS.items():
        print(f"  {preset_name}: {preset['name']} ({preset['estimated_time']}åˆ†é’Ÿ)")
    
    # æ¨èç­–ç•¥åºåˆ—
    print(f"\nğŸ” ç­–ç•¥æ¨èåˆ†æ")
    sequences = {
        '30åˆ†é’Ÿå¿«é€Ÿ': manager.recommend_strategy_sequence(30, 3.0, "ä¸­"),
        '60åˆ†é’Ÿå¹³è¡¡': manager.recommend_strategy_sequence(60, 5.0, "ä¸­"), 
        '120åˆ†é’Ÿæ·±åº¦': manager.recommend_strategy_sequence(120, 7.0, "é«˜")
    }
    
    return manager, sequences

if __name__ == "__main__":
    create_strategy_manager_demo() 