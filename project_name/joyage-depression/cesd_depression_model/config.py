"""
Configuration settings for CESD Depression Prediction Model
"""

# è§£å†³Windowsä¸Šçš„CPUæ ¸å¿ƒæ£€æµ‹è­¦å‘Š
import os
os.environ['LOKY_MAX_CPU_COUNT'] = '24'

# åˆ†ç±»å˜é‡åˆ—è¡¨ (ğŸ”‘ åŸå§‹é«˜æ€§èƒ½ç‰ˆæœ¬çš„å®é™…é…ç½®)
CATEGORICAL_VARS = [
    'ragender', 'raeducl', 'mstath', 'rural', 'shlta', 'hlthlm', 'hibpe', 'diabe',
    'cancre', 'lunge', 'hearte', 'stroke', 'arthre', 'livere', 'drinkev', 'smokev',
    'stayhospital', 'hipriv', 'momliv', 'dadliv', 'ramomeducl', 'radadeducl',
    'lvnear', 'kcntf', 'socwk', 'work', 'pubpen', 'peninc',
    'ftrsp', 'ftrkids', 'painfr', 'fall',
    'adlfive',  # æ–°å¢åˆ†ç±»å˜é‡
]

# éœ€è¦æ’é™¤çš„IDç›¸å…³å˜é‡
EXCLUDED_VARS = ['ID', 'householdID', 'interview_year']

# æ•°å€¼å˜é‡åˆ—è¡¨ (ğŸ”‘ åŸå§‹é«˜æ€§èƒ½ç‰ˆæœ¬çš„å®é™…é…ç½®)
NUMERICAL_VARS = [
    'agey', 'child', 'comparable_hexp', 'hhres',
    'comparable_exp', 'comparable_itearn', 'comparable_frec', 
    'comparable_tgiv', 'comparable_ipubpen'  # æ–°å¢æ•°å€¼å˜é‡
]

# æœºå™¨å­¦ä¹ æ¨¡å‹è¶…å‚æ•°æœç´¢ç©ºé—´å®šä¹‰
MODEL_PARAMS = {
    'random_forest': {
        'n_estimators': [50, 100, 200],
        'max_depth': [5, 10, 15, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4],
        'max_features': ['sqrt', 'log2', None]
    },
    'gradient_boosting': {
        'n_estimators': [50, 100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    },
    # ğŸš« ç”¨æˆ·è¦æ±‚ï¼šå®Œå…¨ç¦ç”¨SVCæ¨¡å‹ï¼ˆé¿å…é•¿æ—¶é—´è®­ç»ƒï¼‰
    # 'svc': {
    #     'base_estimator__C': [0.1, 1, 10],  # LinearSVCçš„Cå‚æ•°
    #     'base_estimator__max_iter': [5000]  # å›ºå®šè¿­ä»£æ¬¡æ•°
    # },
    'logistic_regression': {
        'C': [0.01, 0.1, 1, 10, 100],
        'penalty': ['l1', 'l2'],
        'solver': ['liblinear', 'saga'],
        'max_iter': [1000, 2000]
    },
    'xgboost': {
        'n_estimators': [50, 100, 200],
        'max_depth': [3, 5, 7],
        'learning_rate': [0.01, 0.1, 0.2],
        'subsample': [0.8, 0.9, 1.0],
        'colsample_bytree': [0.8, 0.9, 1.0]
    },
    'lightgbm': {
        'n_estimators': [50, 100, 200],
        'max_depth': [3, 5, 7, -1],
        'learning_rate': [0.01, 0.1, 0.2],
        'num_leaves': [31, 50, 100],
        'subsample': [0.8, 0.9, 1.0]
    }
}

# äº¤å‰éªŒè¯è®¾ç½®ï¼ˆä½¿ç”¨10æŠ˜è·å¾—æœ€å‡†ç¡®è¯„ä¼°ï¼‰
CV_SETTINGS = {
    'outer_splits': 10,  # 10æŠ˜äº¤å‰éªŒè¯
    'inner_splits': 10,
    'random_state': 42,
    'n_splits': 10  # ç»Ÿä¸€ä½¿ç”¨10æŠ˜
}

# æ–‡ä»¶è·¯å¾„è®¾ç½®
FILE_PATHS = {
    'model_save_dir': 'saved_models',
    'results_dir': 'results',
    'plots_dir': 'plots',
    'logs_dir': 'logs'
}

# SMOTEå‚æ•°
SMOTE_PARAMS = {
    'random_state': 42,
    'k_neighbors': 5,
    'sampling_strategy': 'auto'
}

# è¯„ä¼°æŒ‡æ ‡è®¾ç½®
METRICS = [
    'accuracy',
    'precision',
    'recall',
    'f1',
    'roc_auc',
    'average_precision',
    'brier_score'
]

# ========== èµ„æºè‡ªé€‚åº”å¹¶è¡Œå‚æ•° ==========
import os
try:
    import psutil
    def get_total_memory_gb():
        mem = psutil.virtual_memory()
        return mem.total / (1024 ** 3)
except ImportError:
    def get_total_memory_gb():
        # psutilä¸å¯ç”¨æ—¶ï¼Œè¿”å›ä¸€ä¸ªä¿å®ˆå€¼
        return 8

def get_optimal_n_jobs(per_job_gb=3, max_ratio=0.5):
    """
    è®¡ç®—æœ€ä¼˜å¹¶è¡Œä½œä¸šæ•°
    
    å‚æ•°:
    ----
    per_job_gb : float, é»˜è®¤3
        æ¯ä¸ªä½œä¸šé¢„ä¼°å†…å­˜éœ€æ±‚(GB)
    max_ratio : float, é»˜è®¤0.5
        æœ€å¤§ä½¿ç”¨CPUæ ¸å¿ƒæ•°çš„æ¯”ä¾‹
    """
    total_memory_gb = get_total_memory_gb()
    cpu_count = os.cpu_count() or 1
    
    # åŸºäºå†…å­˜é™åˆ¶çš„æœ€å¤§ä½œä¸šæ•°
    memory_based_jobs = int(total_memory_gb // per_job_gb)
    
    # åŸºäºCPUé™åˆ¶çš„æœ€å¤§ä½œä¸šæ•°ï¼ˆä¸è¶…è¿‡CPUæ ¸å¿ƒæ•°çš„50%ï¼‰
    cpu_based_jobs = max(1, int(cpu_count * max_ratio))
    
    # ä¸ºå¤§æ•°æ®é›†è®¾ç½®æ›´ä¿å®ˆçš„ä¸Šé™
    conservative_limit = min(8, cpu_count // 2) if cpu_count > 8 else min(4, cpu_count)
    
    # å–ä¸‰è€…æœ€å°å€¼
    optimal_jobs = max(1, min(memory_based_jobs, cpu_based_jobs, conservative_limit))
    
    return optimal_jobs

# ä½¿ç”¨æ›´ä¿å®ˆçš„å‚æ•°
N_JOBS = get_optimal_n_jobs(per_job_gb=3, max_ratio=0.4)

# ========== ä¼˜åŒ–å®Œæˆ ==========
# æ–¹æ¡ˆ1ï¼šæ™ºèƒ½N_JOBSè®¡ç®—å·²å¯ç”¨
# å½“å‰N_JOBSå€¼ä¼šæ ¹æ®ç³»ç»Ÿé…ç½®è‡ªåŠ¨è®¡ç®—
# ========================================= 